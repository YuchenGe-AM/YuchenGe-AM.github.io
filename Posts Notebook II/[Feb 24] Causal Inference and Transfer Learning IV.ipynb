{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4ecbc3a",
   "metadata": {},
   "source": [
    "## [Feb 21] Causal Inference and Transfer Learning\n",
    "\n",
    "Presenter: Yuchen Ge  \n",
    "Affiliation: University of Oxford  \n",
    "Contact Email: gycdwwd@gmail.com  \n",
    "Website: https://yuchenge-am.github.io"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c723a98-16e1-4224-997f-2b80431b4d02",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 1. Multivariate Causal Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacddc8c-47d8-4ad9-aa7c-ed309b5bbbcf",
   "metadata": {},
   "source": [
    "In **causal inference**, we assume that **for a graph $\\exists$ at most one edge between any two vertices [ Peter Spirtes. Causation, Prediction, and Search. P28 ]**. Recall that \n",
    "\n",
    "> A SCM $\\mathfrak{C}$ defines $X_{j}:=f_{j}\\left(\\mathbf{P A}_{j}, N_{j}\\right)$ on a DAG.\n",
    ">\n",
    "> (**randomized experiments**) An intervention $P_{\\mathbf{X}}^{\\tilde{\\mathbb{C}}}=: P_{\\mathbf{X}}^{\\mathfrak{C} ; d o\\left(X_{k}:=\\tilde{f}\\left(\\widetilde{\\mathbf{P A}_{k}}, \\tilde{N}_{k}\\right)\\right)}$ is defined via setting $X_k:=\\tilde{f}\\left(\\widetilde{\\mathbf{P A}}_{k}, \\tilde{N}_{k}\\right)$. An intervention with $\\widetilde{\\mathbf{P A}}_{k}=\\mathbf{P A}_{k}$ is called imperfect. \n",
    ">\n",
    "> A counterfactual SCM is $\\mathfrak{C}_{\\mathbf{X}=\\mathbf{x}}:=\\left(\\mathbf{S}, P_{\\mathbf{N}}^{\\mathfrak{C} \\mid \\mathbf{X}=\\mathbf{x}}\\right)$ where $P_{\\mathbf{N}}^{\\mathfrak{C} \\mid \\mathbf{X}=\\mathbf{x}}:=P_{\\mathbf{N} \\mid \\mathbf{X}=\\mathbf{x}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15312391-dc98-436d-ad76-d5cce6a4f31e",
   "metadata": {},
   "source": [
    "TFAE: \n",
    "1. **global Markov property**: $\\mathbf{A} \\perp_{\\mathcal{G}} \\mathbf{B}|\\mathbf{C} \\Rightarrow \\mathbf{A} \\perp \\mathbf{B}| \\mathbf{C}$.\n",
    "2. **local Markov property**:each variable is independent of its non-descendants given its parents.\n",
    "3. **Markov factorization property**:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aae6a87-8808-4a92-be15-c517d63e227a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c9bbf9-c040-4158-b7c4-6f533e2bc2f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1a6066-9047-488c-8aec-5626b8bec05b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec66c49-c3fb-41b5-add5-aa93a4f11ff8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b92e7bfd-05d9-4727-9d73-037d1a825413",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488bf885-78c7-44b2-b10a-80841cf79827",
   "metadata": {},
   "source": [
    "Then we shall formulate the causal discovery problem. Let  $\\mathbf{G}$  be the set of graphs defined over the variables $ \\mathbf{V}$  of a data set  $\\mathbf{D}$  and  $G^{*} \\in \\mathbf{G}$.\n",
    "\n",
    "> ( **Causal Discovery Problem** ). The causal discovery problem consists in recovering $G^{*}$  from given $D$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b0bdd1-08ee-4fea-bbed-abc391018fe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4b8def-934a-4a5b-83d2-ada44aef8d24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b90c525-fafc-4362-b64c-1e3180d85bb9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "091f423a-b8e3-40ce-b565-463a5fdbdd54",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> [ **Thomas Richardson. Ancestral Graph Markov Models. Appendix.** ] Let  $\\mathcal{E}=\\{-, \\leftarrow, \\rightarrow, \\leftrightarrow\\}$  be the set of edges.  A mixed graph is a pair $\\mathscr{g}=(V, E)$  with $E: V \\times V \\rightarrow \\mathcal{P}(\\mathcal{E})$ subject to \n",
    "> $$\\begin{aligned}\n",
    "E(\\alpha, \\alpha)=\\varnothing, & \\quad -\\in E(\\alpha, \\beta) \\Longleftrightarrow-\\in E(\\beta, \\alpha), \\\\\n",
    "\\leftarrow \\in E(\\alpha, \\beta) \\Longleftrightarrow \\rightarrow \\in E(\\beta, \\alpha), & \\quad   \\leftrightarrow \\in E(\\alpha, \\beta) \\Longleftrightarrow \\leftrightarrow \\in E(\\beta, \\alpha) .\n",
    "\\end{aligned}$$\n",
    ">\n",
    "> An **ADMG** is a mixed graph containing no directed cycles, which can be viewed as a DAG adding  bidirected arrows ($\\leftrightarrow$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c2435c-f61c-4290-aaf9-758fff79cb95",
   "metadata": {},
   "source": [
    "If $a \\leftrightarrow b$, then $a$ is a sibling of $b$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e19cccb-d422-4572-b709-d4dc470b6659",
   "metadata": {},
   "source": [
    "> ( **Latent projection of a DAG** )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da4e08a-dbe4-44ea-ac2f-15b690a4f22a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76512fdb-e3a1-4134-8799-8f2a3df0d831",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "98f28c99-02ff-45bf-ac85-baba30c40ef6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Reference\n",
    "\n",
    "1. Shuxiao Chen. Minimax Rates and Adaptivity in Combining Experimental and Observational Data.\n",
    "2. Qingyuan Zhao. Lecture Notes on Causal Inference. \n",
    "3. Joaquin Quiñonero-Candela. Dataset Shift In Machine Learning.\n",
    "4. Geoff K. Nicholls. Bayes Methods.\n",
    "5. Patrick J. Laub. Hawkes Processes.\n",
    "6. Tomas Björk. An Introduction to Point Processes from a Martingale Point of View.\n",
    "7. Jonas Peters. Elements of Causal Inference.\n",
    "8. Alessio Zanga. A Survey on Causal Discovery.\n",
    "9. Qing Zhou. Directed Mixed Graphs for Latent Variables.\n",
    "10. Peter Spirtes. Causation, Prediction, and Search. \n",
    "11. Thomas Richardson. Ancestral Graph Markov Models.\n",
    "12. Jonas Peters. Causal Inference Using Invariant Prediction."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
