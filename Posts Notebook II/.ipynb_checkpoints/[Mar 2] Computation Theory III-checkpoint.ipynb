{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4ecbc3a",
   "metadata": {},
   "source": [
    "## [Mar 2] Computation Theory III\n",
    "\n",
    "Presenter: Yuchen Ge  \n",
    "Affiliation: University of Oxford  \n",
    "Contact Email: gycdwwd@gmail.com  \n",
    "Website: https://yuchenge-am.github.io"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9f4f87-8543-42fb-9743-918cd46c4d70",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9789ca6a-2827-4b30-9878-eef18193a80d",
   "metadata": {},
   "source": [
    "### 1. Graph Representation Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6b0c93-e949-47c6-bdd6-ef1fed8766bf",
   "metadata": {},
   "source": [
    "Assume edges are unweighted and undirectional. Each node  $v_{i} \\in \\mathcal{V}$  associates  $D$-dimensional feature vector  $\\mathbf{x}_{i} \\in \\mathbb{R}^{1 \\times D}$, and then stack the feature vectors into a single matrix $\\mathbf{X} \\in \\mathbb{R}^{N \\times D}$. A message passing GNN layer  $l$  is computed as\n",
    "\n",
    "$$\\mathbf{x}_{i}^{(l+1)}=\\phi\\left(\\mathbf{x}_{i}^{(l)}, \\bigoplus_{j \\in \\mathcal{N}\\left(v_{i}\\right)} \\psi\\left(\\mathbf{x}_{i}^{(l)}, \\mathbf{x}_{j}^{(l)}\\right)\\right)$$\n",
    "\n",
    "where $\\bigoplus$ is a  permutation-invariant aggregation function. In practice, we convolve node features with its neighbours \n",
    "\n",
    "$$\\left(\\mathbf{A X}^{(l)}\\right)_{i}=\\sum_{j \\in \\mathcal{N}\\left(v_{i}\\right)} \\mathbf{x}_{j}^{(l)} \\quad \\text{ and } \\quad \\left(\\hat{\\mathbf{A}} \\mathbf{X}^{(l)}\\right)_{i}=\\mathbf{x}_{i}^{(l)}+\\sum_{j \\in \\mathcal{N}\\left(v_{i}\\right)} \\mathbf{x}_{j}^{(l)}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e70d118-1b5f-4f9c-b4e9-b2dc8e687865",
   "metadata": {},
   "source": [
    "> For GCNs, we use $\\underbrace{\\mathbf{X}^{(l+1)}}_{N \\times D_{\\text {out }}}=\\sigma(\\underbrace{\\tilde{\\mathbf{A}}}_{N \\times N} \\underbrace{\\mathbf{X}^{(l)}}_{N \\times D_{i n}} \\underbrace{\\mathbf{W}^{(l)}}_{D_{\\text {in }} \\times D_{\\text {out }}})=\\sigma(\\underbrace{\\hat{\\mathbf{D}}^{-1 / 2}}_{N \\times N} \\underbrace{\\hat{\\mathbf{A}}}_{N \\times N} \\underbrace{\\hat{\\mathbf{D}}^{-1 / 2}}_{N \\times N} \\underbrace{\\mathbf{X}^{(l)}}_{N \\times D_{i n}} \\underbrace{\\mathbf{W}^{(l)}}_{D_{i n} \\times D_{\\text {out }}})$.\n",
    "\n",
    ">\n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c4b829-af10-4182-9aea-cf0d5a524805",
   "metadata": {},
   "source": [
    "Concretely, $\\left(\\hat{\\mathbf{D}}^{-1 / 2} \\hat{\\mathbf{A}} \\hat{\\mathbf{D}}^{-1 / 2} \\mathbf{X}^{(l)} \\mathbf{W}^{(l)}\\right)_{i}=\\left(\\hat{\\mathbf{D}}^{-1 / 2} \\hat{\\mathbf{A}} \\hat{\\mathbf{D}}^{-1 / 2} \\mathbf{X}^{(l)}\\right)_{i} \\mathbf{W}^{(l)}=\\left(c_{i i} \\mathbf{x}_{i}^{(l)}+\\sum_{j \\in \\mathcal{N}\\left(v_{i}\\right)} c_{i j} \\mathbf{x}_{j}^{(l)}\\right) \\mathbf{W}^{(l)}$ where $c_{i j}=\\frac{1}{\\sqrt{\\operatorname{deg}\\left(v_{i}\\right) \\operatorname{deg}\\left(v_{j}\\right)}}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67fdc4f-20ff-41b7-8fdb-6394dde3f7f0",
   "metadata": {},
   "source": [
    "> For multihead GATs, we use $\\underbrace{\\mathbf{X}^{(l+1)}}_{N \\times D_{\\text {out }}}=\\sigma(\\frac{1}{K} \\sum_{k=1}^{K} \\underbrace{\\tilde{\\mathbf{A}}^{(l, k)}}_{N \\times N} \\underbrace{\\mathbf{X}^{(l)}}_{N \\times D_{\\text {in }}} \\underbrace{\\mathbf{W}^{(l, k)}}_{D_{\\text {in }} \\times D_{\\text {out }}}) $ where $\\tilde{\\mathbf{A}}^{(l, k)}=\\tilde{\\mathbf{A}}^{(l, k)}\\left(\\mathbf{X}^{(l)}\\right)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ecaac0-5b57-4335-a7a7-45feb0f38a0b",
   "metadata": {},
   "source": [
    "Intuitively, the operations performed by the transformer block are\n",
    "\n",
    "$$ \\mathrm{h}=\\operatorname{MHSA}(\\operatorname{LayerNorm}(\\mathrm{x}))+\\mathrm{x}, \\text{ and } \\mathrm{y}=\\operatorname{MLP}(\\operatorname{LayerNorm}(\\mathrm{h}))+\\mathrm{h},$$\n",
    "\n",
    "which are complemented with LayerNorms and skip connections, which aid in training. In words, MHSA processes the input feature matrix $\\mathbf{X} \\in \\mathbb{R}^{N \\times D}$ column-wise, whereas MLP row-wise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04740a1b-d9b6-45cc-a2e3-846f7fb8177b",
   "metadata": {},
   "source": [
    "In graph representation learning, each node is a token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656f7034-b280-4302-b95b-92e682932ec8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88479f4-3010-4cc8-8adc-5d0624d19400",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2ecb4e-c538-4850-ab7d-398fc1f6e640",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c7f921-39ad-4241-a240-14afe322a3e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e8fdb22-fb52-4f3f-87c9-b7511ccb46f8",
   "metadata": {},
   "source": [
    "### 2. Relation to Causal Inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5941a5b0-9d61-4419-8dce-e7ec1ed8fd7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fdbfb3-9b69-4da3-a94c-3f5dd550646a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b84fbacb-b54b-4504-b24e-84a1c8b3a800",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88a2fdc7-fd66-4b9d-af4b-becd6ea8c5e6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3d0ef31-f6cf-4439-8197-0cab969d54cf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40ac548a-cffd-49b5-ae00-4a481a8d8dbc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "454fe490-a4c2-4699-b1ea-489f0afd91b2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2a07338-4108-4a80-bef8-da75a7eecd7b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6cd389c-81a4-4013-b9ee-1d2da462111d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c9d8fa1-367c-44ec-aabb-5c30437b48e1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a702f7cb-1f2f-4257-bdb2-c6a870ef6d9f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "219d246d-e796-4435-abff-ade30fa3e43c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5a5b4c-b83c-43b8-a8fb-be163aba1b4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800004c0-97e4-49d0-9e1f-3a302418de83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303ff20d-7f89-454c-8264-e4fc5cb9b62c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c433f0b-1b95-45cd-90ff-ac1002655d60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9db293-5892-4e46-ad51-70a876c04a34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e735da68-f6c4-47dd-bd4f-6e814c636762",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa85cb7-928d-4dd3-a4ee-403aa2dea130",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6791e26-656c-4ada-9944-13dc3620ea03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f477aaa-8f39-407f-8d4b-73c445fa9c46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ccc99125-258b-44b5-8ede-57420ca5fe8c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da4e2f1f-e4cd-403a-9535-8a6cea686089",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03f5331e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Reference\n",
    "\n",
    "1. Elucidating Graph Neural Networks, Transformers, and Graph Transformers.\n",
    "2. Relating Graph Neural Networks to Structural Causal Models. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
