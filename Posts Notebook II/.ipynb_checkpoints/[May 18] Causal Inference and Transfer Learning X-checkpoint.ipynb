{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4ecbc3a",
   "metadata": {},
   "source": [
    "## [May 18] Causal Inference and Transfer Learning X\n",
    "\n",
    "Presenter: Yuchen Ge  \n",
    "Affiliation: University of Oxford  \n",
    "Contact Email: gycdwwd@gmail.com  \n",
    "Website: https://yuchenge-am.github.io\n",
    "\n",
    "We follow the notations in $\\textit{Stochastic Differential Equations and Diffusion Processes}$ by Nobuyuki Ikeda. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd53c1a-7b00-4471-90e9-65cd0ae3c359",
   "metadata": {},
   "source": [
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fd183e-4cbd-4e45-8b0d-139b20201e96",
   "metadata": {},
   "source": [
    "### 1.Itô's Formula "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977e0e2d-ebee-41b2-b6a7-a35945ba6ee9",
   "metadata": {},
   "source": [
    "Recall that for continuous semimartingales, we have\n",
    "\n",
    "> 1. (**Itô's Formula**) If  $X^{1}, X^{2}, \\ldots, X^{d} \\in \\mathscr{Q}$  and  $f \\in \\boldsymbol{C}^{2}\\left(\\boldsymbol{R}^{d} \\longrightarrow \\boldsymbol{R}\\right)$, then $Y=f\\left(X^{1}, X^{2}, \\ldots, X^{d}\\right) \\in \\mathscr{Q}$ and \n",
    ">\n",
    "> $$ d Y=\\sum_{i=1}^{d}\\left(\\partial_{i} f\\right) \\cdot d X^{t}+\\frac{1}{2} \\sum_{i, j=1}^{d}\\left(\\partial_{t} \\partial_{j} f\\right) \\cdot d X^{i} \\cdot d X^{j}.$$\n",
    ">\n",
    "> 2. (**Martingale Characterization Theorem**) If  $d X^{i} \\in d \\mathscr{M}$  and $ d X^{i} \\cdot d X^{j}=\\delta_{i j} d t$, then  $\\left(X^{1}(t), X^{2}(t), \\ldots, X^{d}(t)\\right)$  is a  $d$-dimensional Wiener process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc678a9a-ff10-4e53-b913-18ce4f8e450e",
   "metadata": {},
   "source": [
    "Note that for general $X$ where we set\n",
    "\n",
    "$$ X(t)=X(0) + M(t)+A(t)+\\int_{0}^{t+} \\int_{X} f(s, x, \\cdot) N_{p}(d s d x) + \\int_{0}^{t+} \\int_{X} g(s, x, \\cdot) \\tilde{N}_{p}(d s d x)$$\n",
    "\n",
    "and restrict that $f(s, x, \\omega) g(s, x, \\omega)=0$, it suffices we add \n",
    "\n",
    "$$\\begin{aligned}\n",
    "& \\int_{0}^{t+} \\int_{X}\\{F(X(s-)+f(s, x, \\cdot))-F(X(s-))\\} N_{p}(d s d x) + \\int_{0}^{t+} \\int_{X}\\{F(X(s-)+g(s, x, \\cdot))-F(X(s-))\\} N_{p}(d s d x) \\\\\n",
    "& - \\int_{0}^{t} \\int_{X} \\sum_{i=1}^{d} g^{i}(s, x, \\cdot) F_{i}^{\\prime}(X(s)) \\hat{N}_{p}(d s d x) \\\\\n",
    "= \\text{ } & \\int_{0}^{t+} \\int_{X}\\{F(X(s-)+f(s, x, \\cdot))-F(X(s-))\\} N_{p}(d s d x) + \\int_{0}^{t+} \\int_{X}\\{F(X(s-)+g(s, x, \\cdot))-F(X(s-))\\} \\tilde{N}_{p}(d s d x) \\\\\n",
    "& + \\int_{0}^{t} \\int_{X}\\{F(X(s)+g(s, x, \\cdot))-F(X(s))  -\\sum_{i=1}^{d} g^{i}(s, x, \\cdot) F_{i}^{\\prime}(X(s))\\} \\hat{N}_{p}(d s d x) .\n",
    "\\end{aligned}$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Then we consider **symmetric multiplication** $ Y \\circ d X = Y \\cdot d X+\\frac{1}{2} d X \\cdot d Y$, with which we have $d Y=\\sum_{i=1}^{d} \\partial_{i} f \\circ d X^{t}$. It also assumes a connection with **Fisk integral** \n",
    "\n",
    "$$\\int_0^t Y \\circ d X = \\text{limit in probability of} \\sum_{i=1}^{n} \\frac{1}{2}(Y\\left(t_{t}\\right)+Y\\left(t_{i-1}\\right))\\left(X\\left(t_{i}\\right)-X\\left(t_{i-1}\\right)\\right).$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbf1215-87fb-4a74-b4fe-5906bbd4a744",
   "metadata": {},
   "source": [
    "Finally, with **Itô's formula** and **Holder's inequality** we know that \n",
    "\n",
    "> Fix $0<p<\\infty$ and $M \\in \\mathscr{M} = \\mathscr{M}_{2}^{c, l o c}$, then \n",
    ">\n",
    "> $$c_{p} E\\left(M_{t}^{* 2 p}\\right) \\leq E\\left(\\langle M, M\\rangle_{t}^{p}\\right) \\leq C_{p} E\\left(M_{t}^{* 2 p}\\right) \\text{ for some universal constants } c_{p}, C_{p}$$\n",
    ">\n",
    "> where $M_{t}^{*}=\\max _{0 \\leq s \\leq t}\\left|M_{s}\\right|$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1242186-ba8e-49f8-80ce-8c1b2431b768",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2. Stochastic Differential Equations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f9ec46-96c5-4734-a8a1-95bd7cf6c49d",
   "metadata": {},
   "source": [
    "A **stochastic time change** is some $\\phi=\\left(\\phi_{t}\\right) \\in \\mathscr{A}_{+}$ s.t.  $t \\longmapsto \\phi_{t}$  is strictly increasing and  $\\lim _{t+\\infty} \\phi_{t}=\\infty$. We set $\\tau_{t}=\\inf \\left\\{u ; \\phi_{u}>t\\right\\}$ and then\n",
    "\n",
    "> 1. $\\tau_{t}$  is an  $\\left(\\mathscr{F}_{t}\\right)$-stopping time because  $\\left\\{\\tau_{t} \\leq u\\right\\}=\\left\\{t \\leq \\phi_{u}\\right\\} \\in \\mathscr{F}_{u}$.\n",
    ">\n",
    "> 2. $t \\longmapsto \\tau_{t}$ is continuous, strictly increasing, and with limit $\\infty$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02166688-76eb-4fc4-94de-5ceb9d268f36",
   "metadata": {},
   "source": [
    "It immediately follows that by defing $\\tilde{\\mathscr{F}}_{\\mathrm{t}}=\\mathscr{F}_{\\tau_t}$, we have $\\tilde{\\mathscr{F}}_{\\mathrm{t}}$  is a reference family and the corresponding space of quasimartingales $\\tilde{\\mathscr{Q}}$. It can be checked that\n",
    "\n",
    "> $T^{\\phi}: \\mathscr{Q} \\longrightarrow \\tilde{\\mathscr{Q}}$ where $\\left(T^{\\phi} X\\right)_{t}=X_{\\tau_{t}}$ is a bijection which **preserves all\n",
    "structures** on the space of quasimartingales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b11465-24db-4c36-820d-f45e8d1e2573",
   "metadata": {},
   "source": [
    "Since all operations in  $\\mathscr{Q}$  are defined in terms of addition, the operation  $\\langle M, N\\rangle$  and stochastic integration, the assertion is obvious by checking these operations. Specially, we know $T^{\\phi}(X \\circ d Y)=\\left(T^{\\phi} X\\right) \\circ T^{\\phi}(d Y)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbee77e-92dd-4b36-9a31-7fc417d8815a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Next, we set $X^{i} \\in \\mathscr{Q}$  and $\\left(\\sigma_{j}^{i}(x)\\right)$  of real locally bounded Borel measurable functions on  $\\boldsymbol{R}^{d}$. Consider  $Y^{i}\\in \\mathscr{Q}$ s.t.\n",
    "\n",
    "$$d Y^{i}(t)=\\sum_{j} \\sigma_{j}^{i}(Y(t)) \\cdot d X^{j}(t)$$\n",
    "\n",
    "where $Y(t) = (Y^{j}(t), j \\in [d])$. \n",
    "\n",
    "> Suppose that $\\sigma_{j}^{i}$ satisfies a Lipschitz condition, then for each given  $y=\\left(y^{j}, j \\in [d] \\right) \\in \\boldsymbol{R}^{d}$, $\\exists ! Y(t)$ s.t. \n",
    ">\n",
    "> $$ Y^{i} \\in \\mathscr{Q}, Y^{i}(0)=y^{i} \\text{ and the SDE is satisfied. } $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65513745-126e-42d3-87b2-15ab50e5c27e",
   "metadata": {},
   "source": [
    "We consider a special case \n",
    "\n",
    "$$d Y=a_{1}(Y(t)) \\cdot d M+a_{2}(Y(t)) \\cdot d A$$\n",
    "\n",
    "where $M \\in \\mathscr{M}, A \\in \\mathscr{A}$, then we consider $\\phi(t)=t+\\langle M\\rangle_{t}+ \\boldsymbol{|} A \\boldsymbol{|}_{t}$ and an application of the **picard sequence** and **Borel-Cantelli's lemma** gives the proof. Here $\\boldsymbol{|} \\cdot \\boldsymbol{|}_{t}$ denotes the total variation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f28c99-02ff-45bf-ac85-baba30c40ef6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Reference\n",
    "\n",
    "1. Shuxiao Chen. Minimax Rates and Adaptivity in Combining Experimental and Observational Data.\n",
    "2. Qingyuan Zhao. Lecture Notes on Causal Inference. \n",
    "3. Joaquin Quiñonero-Candela. Dataset Shift In Machine Learning.\n",
    "4. Geoff K. Nicholls. Bayes Methods.\n",
    "5. Patrick J. Laub. Hawkes Processes.\n",
    "6. Tomas Björk. An Introduction to Point Processes from a Martingale Point of View.\n",
    "7. Jonas Peters. Elements of Causal Inference.\n",
    "8. Alessio Zanga. A Survey on Causal Discovery.\n",
    "9. Qing Zhou. Directed Mixed Graphs for Latent Variables.\n",
    "10. Peter Spirtes. Causation, Prediction, and Search. \n",
    "11. Thomas Richardson. Ancestral Graph Markov Models.\n",
    "12. Jonas Peters. Causal Inference Using Invariant Prediction.\n",
    "13. Jonathan Baxter. A Bayesian/Information Theoretic Model of Learning to Learn via Multiple Task Sampling."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
