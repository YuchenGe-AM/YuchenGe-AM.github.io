{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4ecbc3a",
   "metadata": {},
   "source": [
    "## Causal Inference VIII\n",
    "\n",
    "Presenter: Yuchen Ge  \n",
    "Affiliation: University of Oxford  \n",
    "Contact Email: gycdwwd@gmail.com  \n",
    "Website: https://yuchenge-am.github.io\n",
    "\n",
    "The following is first reading of $\\textit{Point Processes and Their Statistical Inference}$ by Alan Karr."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd53c1a-7b00-4471-90e9-65cd0ae3c359",
   "metadata": {},
   "source": [
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce220575-10d1-4295-9052-f5f969ff0c7c",
   "metadata": {},
   "source": [
    "### 1. Random Measure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5f0a4c-2564-4cef-8a54-468f18db770b",
   "metadata": {},
   "source": [
    "We consider a probability space $(\\Omega, \\mathcal{F}, P)$  and set \n",
    "\n",
    "> $(E$, $\\mathcal{E})$ = LCCB space (locally compact $T_2$ space with a countable base) with ring of bounded Borel sets $\\mathcal{B}$.\n",
    ">\n",
    "> $ \\mathbf{M} = \\{\\text {Radon measures}$ on $\\mathcal{B}\\} = \\{\\mu: \\mu(A)<\\infty, \\forall A \\in \\mathcal{B} \\}$.\n",
    ">\n",
    "> A **random measure** on  $E$  is a measurable mapping  $M$: $(\\Omega, \\mathcal{F}) \\to (\\mathbf{M}, \\mathcal{M})$ where $\\mathcal{M}=\\sigma\\left(\\mu \\rightarrow \\mu(f): f \\in C_{K}\\right)$. It can be considered as a random distribution of mass/charge.\n",
    "\n",
    "A Radon measure  $\\mu$  can be decomposed as\n",
    "\n",
    "$$\\mu=\\mu_{d}+\\sum_{i=1}^{K} a_{i} \\varepsilon_{x_{i}}$$\n",
    "\n",
    "where $\\mu_{d}$ is diffuse, $0 \\leq K \\leq \\infty$, $a_{i}>0$. Inspired from the decomposition, we define $\\mathbf{M}_{d}$ = totality of diffuse random measures, $\\mathbf{M}_{p}$ = $\\{\\mu \\in \\mathbf{M}: \\mu(A) \\in \\mathbf{N}, \\forall A \\in \\mathcal{B}\\}$, and $\\mathbf{M}_{s}$ = $\\left\\{\\mu \\in \\mathbf{M}_{p}: \\mu(\\{x\\}) \\leq 1\\right\\}$ with corresponding trace $\\sigma$-algebras. \n",
    "\n",
    "> A point process on  $E$  is a measurable mapping  $N$: $(\\Omega, \\mathcal{F})\\to  \\left(\\mathbf{M}_{p}, \\mathcal{M}_{p}\\right)$.\n",
    ">\n",
    "> A simple point process $N$ is a measurable mapping  $N$: $(\\Omega, \\mathcal{F})\\to  \\left(\\mathbf{M}_{s}, \\mathcal{M}_{s}\\right)$. (e.g. empirical process $ N=\\sum_{i=1}^{n} \\varepsilon_{X_{i}}$ with i.i.d. $X_{i}$'s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b25bfa-57e0-40fd-a2fe-307c40cee123",
   "metadata": {},
   "source": [
    "For a point process, $\\exists$ a representation \n",
    "$$N=\\sum_{i=1}^{K} \\varepsilon_{X_{i}}$$ \n",
    "\n",
    "where the $X_{i}:(\\Omega, \\mathcal{F}) \\to (E, \\mathcal{E})$ are measurable. Then we know $N(f) = \\int_{E} f(x) M(d x) = \\sum_{i=1}^{K} f\\left(X_{i}\\right)$. If it's moreover simple, the points  $X_{i}$  are distinct a.s.and on  $\\mathbf{R}_{+}$ we may take  $0 \\leq T_{1}< T_{2}< \\ldots$ \n",
    "\n",
    "For $P\\left\\{M \\text{ is purely atomic} \\right\\}=1$, above generaizes to $M=\\sum_{i=1}^{K} U_{i} \\varepsilon_{X_{i}}$ where $U_i \\geq 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87be9f84-48f4-4a53-93a2-153b055d3a31",
   "metadata": {},
   "source": [
    "> Complete knowledge of $M$ over a set $A$ is $\\mathcal{F}^{M}(A)=\\sigma(M(B): B \\in \\mathcal{E}, B \\subseteq A)$. In short, $\\mathcal{F}^{M}=\\mathcal{F}^{M}(E)$. \n",
    "\n",
    "Distribution of $N$ is the probability measure $\\mathcal{L}_{N}=P N^{-1}$ on $\\left(\\mathbf{M}_{p}, \\mathcal{M}_{p}\\right)$ and equality in distribution is written as $N_{1} \\stackrel{d}{=} N_{2}$. The Laplace functional of $N$  is the mapping  $L_{N}(f)=E\\left[e^{-N(f)}\\right]=E\\left[e^{-\\sum_{i} f\\left(X_{i}\\right)}\\right]$ where  $f \\in \\mathcal{E}^{+}$. \n",
    "\n",
    "> 1. For a Poisson process $N$ with mean measure  $\\mu$, $L_{N}(f)=\\exp \\left[-\\int_{E}\\left(1-e^{-f}\\right) d \\mu\\right]$.\n",
    ">\n",
    "> 2. For a Cox process $N$ directed by the random measure  $M$, $L_{N}(f)=L_{M}\\left(1-e^{-f}\\right)$.\n",
    "\n",
    "The following provides the connection between distribution and the Laplace functional.\n",
    "\n",
    "> 1. $L_{N_{1}}(f)=L_{N_{2}}(f), \\forall f \\in \\mathcal{E}^{+}$ $\\implies$ $N_{1} \\stackrel{d}{=} N_{2} $.\n",
    ">\n",
    "> 2. $L_{N_{n}}(f) \\rightarrow L_{N}(f), \\forall$ nonnegative $f \\in C_{K}$ $\\implies$ $N_{n} \\xrightarrow{d} N$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6b0496-e9f4-4c83-846a-223dd3244216",
   "metadata": {},
   "source": [
    "We prove 1 only: first observe $\\{\\mu: \\mu(A)=0\\}$ constitute a $\\pi$-system on $\\mathbf{M}_{s}$ generating $\\mathcal{M}_{s}$, then apply the Dynkin $\\pi-\\lambda$ theorem.\n",
    "\n",
    "> The mean measure is given by $\\mu_{N}(A)=E[N(A)]$. $N$ is integrable if  $\\mu_{N} \\in \\mathbf{M}$. \n",
    ">\n",
    "> More generally, consider $N^{k}\\left(d x_{1}, \\ldots, d x_{k}\\right)=N\\left(d x_{1}\\right) \\cdots N\\left(d x_{k}\\right)$, then the moment measure of order $k$ is $\\mu_{N}^{k}=E\\left[N^{k}\\right]$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658ffc97-c1d9-4658-8b7b-bee12f175dab",
   "metadata": {},
   "source": [
    "Finally we introduce marked point processes $\\big($ $\\text{of the form }\\bar{N}=\\sum_{i} \\varepsilon_{\\left(X_{i}, Z_{i}\\right)}$ on LCCB spaces $E$ and $E^{\\prime}$ correspondingly  where $E^{\\prime}$ = mark space $\\big)$, which are fundamental models in studying compound, thinned, and cluster processes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da642df-a394-4fb9-82c7-4d09e0cff135",
   "metadata": {},
   "source": [
    "\n",
    "> **Position dependent marking** refers to $P\\left\\{Z_{i} \\in B \\mid N\\right\\}=K\\left(X_{i}, B\\right)$. Then we know $L_{\\bar{N}}(f) = E\\left[E\\left[e^{-\\sum f\\left(X_{i}, Z_{i}\\right)} \\mid N\\right]\\right] =$ $L_{N}(H)$ where \n",
    ">\n",
    "> $$ H(x)=-\\log \\left[\\int_{E^{\\prime}} e^{-f(x, z)} K(x, d z)\\right]. $$\n",
    "> \n",
    "> **Position independent marking** refers to $Z_{i}$ are i.i.d. and independent of $N$. Then we know $L_{\\bar{N}}(f) = L_{N}(H)$ where\n",
    ">\n",
    "> $$ H(x)=-\\log \\left[\\int_{E^{\\prime}} e^{-f(x, z)} \\rho(d z)\\right]. $$\n",
    "\n",
    "Consider $\\bar{N}=\\sum \\varepsilon_{\\left(X_{i}, \\tilde{N}_{i}\\right)}$ where $\\tilde{N}_i \\in \\mathbf{M}_{p}(\\tilde{E})$ for some LCCB space $\\tilde{E}$. A **clustered point process** is the corresponding $\\tilde{N}=\\sum_{i} \\tilde{N}_{i}$. It admits a connection with **infinitely divisibility**. A Poisson process is clearly infinitely divisibile since  \n",
    "\n",
    "$$ L_{N}(f)=\\left(\\exp \\left[-(1 / n) \\int\\left(1-e^{-f}\\right) d \\mu\\right]\\right)^{n}=\\prod_{i=1}^{n} L_{N_{i}}(f) $$\n",
    "\n",
    "for some poission processes $N_{i}$'s. More generally for integrable $\\tilde{N}$,  infinitely divisible $\\Longleftrightarrow$ it's a Poisson cluster process $\\big($i.e. $\\sum \\varepsilon_{X_{i}}$ is Poisson and $\\bar{N}$ is obtained from $N$ via position-dependent marking$\\big)$. The following class of infinitely divisible random measures is particularly amenable to analysis.\n",
    "\n",
    "> A random measure $M$ with independent increments $\\big($i.e. $M\\left(A_{1}\\right), \\ldots, M\\left(A_{k}\\right)$ are independent with disjoint $A_{1}, \\ldots, A_{k}\\big)$ assumes an **infinitely divisible part with independent increments**.\n",
    "\n",
    "\n",
    "\n",
    "Consider $\\bar{N}=\\sum \\varepsilon_{\\left(X_{i}, U_{i}\\right)}$ with position-dependent marking on $\\mathbf{R}_{+}$ using a transition kernel $K$. A **compound point process** is the corresponding \n",
    "\n",
    "$$M=\\sum_{i} U_{i} \\varepsilon_{X_{i}}.$$\n",
    "\n",
    "If moreover $P\\left\\{U_{i}=1 \\mid N\\right\\}=1-P\\left\\{U_{i}=0 \\mid N\\right\\}=p\\left(X_{i}\\right)$ for some $p: E \\to [0,1]$, we say $M$ is a **$p$-thinning** of $N$ with corresponding \n",
    "\n",
    "$$L_{M}(f) = L_{N}\\left(-\\log \\left\\{1-p-p e^{-f}\\right\\}\\right).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e42572-9eee-44fa-b59d-e9fe8b293a35",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2. Marked Point Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e162f1-cb81-4d61-ba1a-38123cea6ffb",
   "metadata": {},
   "source": [
    "Let $N=\\sum_{n=1}^{\\infty} \\varepsilon_{\\left(T_{n}, Z_{n}\\right)}$  be a marked point process on  $\\mathbf{R}_{+}$ with mark space  $(E, \\mathcal{E})$. Throughout we assume $\\sum_{n=1}^{\\infty} \\varepsilon_{T_{n}}$ is simple.\n",
    "\n",
    "> Write $N_{t}(B)=\\sum_{n=1}^{\\infty} \\mathbf{1}\\left(T_{n} \\leq t, Z_{n} \\in B\\right), \\text { with } N_{t}=N_{t}(E)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3832603a-d45e-482b-aa42-e8e221c68d56",
   "metadata": {},
   "source": [
    "We're interested in the structure of the **internal\n",
    "history** $\\mathcal{F}_{t}^{N}=\\sigma\\left(N_{s}(B): 0 \\leq s \\leq t, B \\in \\mathcal{E}\\right)$, virtually all of which is inherited by $\\tilde{\\mathcal{F}}_{t}^{N}=\\mathcal{F}_{t}^{N} \\bigvee \\mathcal{N}$.\n",
    "\n",
    "> $\\mathcal{F}_{T}^{N}=\\left\\{\\Lambda \\in \\mathcal{F}_{\\infty}^{N}: \\Lambda \\cap\\{T \\leq t\\} \\in \\mathcal{F}_{t}^{N}\\right\\}$ and $\\mathcal{F}_{T-}^{N}=\\sigma\\left(\\Lambda \\cap\\{T>t\\}: t \\geq 0, \\Lambda \\in \\mathcal{F}_{t}^{N}\\right) \\vee \\mathcal{F}_{0}^{N}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df32011e-87be-48e2-a6ff-6f4d07bce0e1",
   "metadata": {},
   "source": [
    "From definition, $\\mathcal{F}_{t}^{N} \\subseteq \\mathcal{F}_{T}^{N}$ and $\\mathcal{F}_{t-}^{N}=\\mathcal{F}^{N}([0, t))$ for any $t$. Also We have $\\mathcal{F}_{T-}^{N} \\subseteq \\mathcal{F}_{T}^{N}$ and $T \\in \\mathcal{F}_{T-}^{N}$. We list more useful properties.\n",
    "\n",
    "> 1. $\\mathcal{F}_{t}^{N}=\\sigma\\left(\\mathbf{1}\\left(T_{n} \\leq s, Z_{n} \\in B\\right)\\right)$ and $\\mathcal{F}_{t-}^{N}=\\sigma\\left(\\mathbf{1}\\left(T_{n} < s, Z_{n} \\in B\\right)\\right)$, which follows that $\\mathcal{F}_{t}^{N}=\\bigcap_{h>0} \\mathcal{F}_{t+h}^{N}$ (right-continuous).\n",
    ">\n",
    "> 2. $\\mathcal{F}_{T}^{N}=\\sigma\\left(N_{T \\wedge s}(B): s \\geq 0, B \\in \\mathcal{E}\\right)$  is generated by some stopped processes, which follows via some monotone class theorem that\n",
    ">\n",
    "> $$ \\begin{aligned}\n",
    "\\mathcal{F}_{T_{n}}^{N} & =\\sigma\\left(\\left(T_{1}, Z_{1}\\right), \\ldots,\\left(T_{n}, Z_{n}\\right)\\right) \\\\\n",
    "\\mathcal{F}_{T_{n}-}^{N} & =\\sigma\\left(\\left(T_{1}, Z_{1}\\right), \\ldots,\\left(T_{n-1}, Z_{n-1}\\right), T_{n}\\right).\n",
    "\\end{aligned}$$\n",
    ">\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb782c7-01fd-46c5-a53f-2d133e952367",
   "metadata": {},
   "source": [
    "After that, we know from $\\left\\{N_{T \\wedge t}(B)=k\\right\\} \\cap\\left\\{T_{n} \\leq T<T_{n+1}\\right\\}=\\left\\{N_{T_{n} \\wedge t}(B)=k\\right\\} \\cap\\left\\{T_{n} \\leq T<T_{n+1}\\right\\}$ that \n",
    "\n",
    "> $ \\mathcal{F}_{T}^{N} \\cap\\left\\{T_{n} \\leq T<T_{n+1}\\right\\}=\\mathcal{F}_{T_{n}}^{N} \\cap\\left\\{T_{n} \\leq T<T_{n+1}\\right\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1217eb-ba7e-4605-8abc-6f15e9d0489c",
   "metadata": {},
   "source": [
    "Also from $T \\mathbf{1}\\left(T_{n} \\leq T<T_{n+1}\\right)=g_{n}\\left(T_{1}, Z_{1}, \\ldots, T_{n}, Z_{n}\\right) \\mathbf{1}\\left(T_{n} \\leq T<T_{n+1}\\right)$, we can write $U_{n}=\\left[g_{n}\\left(T_{1}, Z_{1}, \\ldots, T_{n}, Z_{n}\\right)-T_{n}\\right]^{+}$ and see that \n",
    "\n",
    "> $\\exists$ $U_{n} \\in \\mathcal{F}_{T_{n}}^{N}$ s.t. $T \\wedge T_{n+1}=\\left(T_{n}+U_{n}\\right) \\wedge T_{n+1}$ on  $\\left\\{T_{n} \\leq T\\right\\}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9656542c-e214-4618-a7b1-d1179edc005d",
   "metadata": {},
   "source": [
    "In the following, we consider $N_t(B)$ and suppose\n",
    "> **Assumption I.** $\\mathcal{F}_{t}^{N} \\subseteq \\mathcal{H}_{t}$ and $E\\left[N_{t}\\right]<\\infty$  for each  $t$.\n",
    "\n",
    "We write the compensator of $N_t$ as $A_{t} = \\lim _{n \\rightarrow \\infty} \\sum_{k=0}^{2^{n}-1} E\\left[ N_{(k+1) t / 2^{n}} - N_{k t / 2^{n}} \\mid \\mathcal{H}_{k t / 2^{n}}\\right]$. Actually it can be represented with regular conditional distribution $F_{n}(\\omega, d u)=P\\left\\{U_{n+1} \\in d u \\mid \\mathcal{H}_{T_{n}}\\right\\}(\\omega)$ where $U_{n+1} = T_{n+1}-T_{n}$ and $\\mathcal{H}_{t}=\\mathcal{H}_{0} \\vee \\mathcal{F}_{t}^{N}$. \n",
    "\n",
    "Set $V_{n} \\in \\mathcal{F}_{T_{n}}^{N}$ s.t. $T \\wedge T_{n+1}=\\left(T_{n}+V_{n}\\right) \\wedge T_{n+1}$ on  $\\left\\{T_{n} \\leq T\\right\\}$, then\n",
    "\n",
    "$$\\begin{aligned}\n",
    "E\\left[\\sum_{j=0}^{n-1}\\left[\\int_{0}^{V_{j} \\wedge U_{j+1}} \\frac{F_{j}(d x)}{F_{j}[x, \\infty)} \\right] \\mathbf{1}\\left(T \\geq T_{j}\\right)\\right] & = \\sum_{j=0}^{n-1} E\\left[E\\left[\\int_{0}^{V_{j} \\wedge U_{j+1}} \\frac{F_{j}(d x)}{F_{j}[x, \\infty)} \\mid \\mathcal{H}_{T_{j}}\\right] \\mathbf{1}\\left(T \\geq T_{j}\\right)\\right] \\\\\n",
    "& = \\sum_{j=0}^{n-1} E\\left[E\\left[\\int_{0}^{V_{j}}  \\mathbf{1}\\left(U_{j+1} \\geq x\\right) \\frac{F_{j}(d x)}{F_{j}[x, \\infty)} \\mid \\mathcal{H}_{T_{j}}\\right] \\mathbf{1}\\left(T \\geq T_{j}\\right)\\right] \\\\\n",
    "& = \\sum_{j=0}^{n-1} E\\left[\\int_{0}^{V_{j}} F_{j}(d x) \\mathbf{1}\\left(T \\geq T_{j}\\right)\\right] = E\\left[\\sum_{j=0}^{n-1} \\mathbf{1}\\left(V_{j} \\geq U_{j+1}\\right) \\mathbf{1}\\left(T \\geq T_{j}\\right)\\right] \\\\\n",
    "& = E\\left[\\sum_{j=0}^{n-1}\\left(N_{T \\wedge T_{j+1}}-N_{T \\wedge T_{j}}\\right) \\mathbf{1}\\left(T \\geq T_{j}\\right)\\right] = E\\left[N_{T \\wedge T_{n}}\\right].\n",
    "\\end{aligned}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13638d14-0230-4d79-bc4b-5a435a65539f",
   "metadata": {},
   "source": [
    "Thus we have shown that for any $T < \\infty$, $E\\left[N_{T \\wedge T_{n}}\\right]=\\boldsymbol{E}\\left[B_{T \\wedge T_{n}}\\right]$, where $B_{t} = B_{T_{n}}+\\int_{0}^{t-T_{n}} F_{n}(d x)/F_{n}[x, \\infty)$, $t \\in\\left(T_{n}, T_{n+1}\\right]$. Then we know $A_t = B_t$ and\n",
    "\n",
    "> 1. ($A=A^{\\prime}$)  and  ($P=P^{\\prime}$  on  $\\mathcal{H}_{0}$) $\\implies$ ($P=P^{\\prime}$  on  $\\mathcal{H}_{\\infty}$). It follows that $\\exists$ a stochastic intensity $\\implies$ it's unique. $\\big($a positive, predictable process $\\lambda=\\left(\\lambda_{t}\\right)$  satisfying  $A_{t}=\\int_{0}^{t} \\lambda_{s} d s$  is the **stochastic intensity** of  $N \\big)$\n",
    ">\n",
    "> 2. Suppose $P\\left\\{U_{n+1} \\in d u \\mid \\mathcal{H}_{T_{n}}\\right\\}=f_{n}(u) d u$ then \n",
    ">\n",
    "> $$\\lambda_{t}=\\frac{f_{n}\\left(t-T_{n}\\right)}{\\int_{t-T_{n}}^{\\infty} f_{n}(u) d u}, \\quad t \\in\\left(T_{n}, T_{n+1}\\right].$$\n",
    ">\n",
    "> 3. Suppose $P\\left\\{U_{n+1} \\in d u, Z_{n+1} \\in d x \\mid \\mathcal{H}_{T_{n}}\\right\\}=f_{n}(u, d x) d u$ then \n",
    ">\n",
    "> $$\\lambda_{t}(B)=\\frac{f_{n}\\left(t-T_{n}, B\\right)}{\\int_{t-T_{n}}^{\\infty} f_{n}(u, E) d u}, \\quad t \\in\\left(T_{n}, T_{n+1}\\right].$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd3bfa8-9ecd-4d3c-870b-e6abb6b5bd01",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c2a99b-d225-4be9-9e1d-a27d6187b07c",
   "metadata": {},
   "source": [
    "> Using a construction identical to that used for regular conditional\n",
    "probabilities, $\\exists$ **measure-valued compensator** $A_t$ s.t. \n",
    "> 1. $A_{t}(B)=A([0, t] \\times B)$ is predictable \n",
    "> 2. $M_{t}(\\cdot)=N_{t}(\\cdot)-A_{t}(\\cdot)$ is a measure-valued martingale (**innovation martingale**)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21410452-eb7f-4cd1-8a97-4dceb05251a9",
   "metadata": {},
   "source": [
    "Computation shows that $M_{t}^{2}=2 \\int_{0}^{t} M_{s-} d M_{s}+\\sum_{s \\leq t}\\left(\\Delta M_{s}\\right)^{2}$, which follows that we have a Doob-Meyer decomposition\n",
    "\n",
    "$$ M_{t}^{2}=\\int_{0}^{t}\\left(2 M_{s-}+1-2 \\Delta A_{s}\\right) d M_{s}+\\int_{0}^{t}\\left(1-\\Delta A_{s}\\right) d A_{s} \\implies \\langle M\\rangle_{t}=\\int_{0}^{t}\\left(1-\\Delta A_{s}\\right) d A_{s} .$$\n",
    "\n",
    "If $A$ is continuous in $t$, then $\\Delta A=0$ and $\\langle M\\rangle=A$. Therefore, we have the following interpretation.\n",
    "\n",
    "> From $d\\langle M\\rangle=d A$ and $d A_{t}=E\\left[d N_{t} \\mid \\mathcal{H}_{t-}\\right]$ we know\n",
    ">\n",
    "> $$ E\\left[\\left(d N_{t}-E\\left[d N_{t} \\mid \\mathcal{H}_{t-}\\right]\\right)^{2} \\mid \\mathcal{H}_{t-}\\right]=d A_{t}=E\\left[d N_{t} \\mid \\mathcal{H}_{t-}\\right]. $$\n",
    ">\n",
    "> That is, **$N_t$ with a continuous $A_t$ is locally and conditionally a Poisson process** in the sense that its mean and variance are equal. Moreover,\n",
    ">\n",
    "> $$\\lambda_{t} d t=E\\left[\\Delta N_{t} \\mid \\mathcal{H}_{t-}\\right]=P\\left\\{\\Delta N_{t}=1 \\mid \\mathcal{H}_{t-}\\right\\}=P\\left\\{\\Delta N_{t}>0 \\mid \\mathcal{H}_{t-}\\right\\}.$$\n",
    "\n",
    "Via computing $\\left\\langle M\\left(B_{1} \\cup B_{2}\\right)\\right\\rangle_{t}=\\left\\langle M\\left(B_{1}\\right)\\right\\rangle_{t}+\\left\\langle M\\left(B_{2}\\right)\\right\\rangle_{t}+2\\left\\langle M\\left(B_{1}\\right), M\\left(B_{2}\\right)\\right\\rangle_{t}$ with different methods, we have\n",
    "\n",
    "> 1. Let $B_1$ and $B_2$ be disjoint. $\\left\\langle M\\left(B_{1}\\right), M\\left(B_{2}\\right)\\right\\rangle_{t}=-\\int_{0}^{t} \\Delta A_{s}\\left(B_{1}\\right) \\Delta A_{s}\\left(B_{2}\\right) d s$\n",
    ">\n",
    "> 2. For general $B_1$ and $B_2$, we know \n",
    "> $$\\left\\langle M\\left(B_{1}\\right), M\\left(B_{2}\\right)\\right\\rangle_{t} =  \\int_{0}^{t}\\left[1-\\Delta A\\left(B_{1} \\cap B_{2}\\right)\\right] d A\\left(B_{1} \\cap B_{2}\\right) -\\int_{0}^{t} \\Delta A\\left(B_{1} \\cap B_{2}\\right) \\Delta A\\left(B_{1} \\Delta B_{2}\\right) d s -\\int_{0}^{t} \\Delta A\\left(B_{1} \\backslash B_{2}\\right) \\Delta A\\left(B_{2} \\backslash B_{2}\\right) d s.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abad998-0ce2-4c52-93fa-6f9a486916ae",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "We can interpret a point process as a dynamic, uncountable set of independent Bernoulli trials. \n",
    "\n",
    "> 1. $P\\big($ successes at $T_{1}, \\ldots, T_{N_{t}}$ over $[0, t] \\big)$ = $\\prod_{k=1}^{N_{t}} \\lambda_{T_{k}}=\\exp \\left[-\\int_{0}^{t}(-\\log \\lambda) d N\\right]$.\n",
    ">\n",
    "> 2. $P\\big($ no successes over $(T_{j-1}, T_{j})\\big)$  =\n",
    "$1-F_{j-1}\\left(T_{j}-T_{j-1}\\right)=\\exp \\left[-\\int_{T_{j-1}}^{T_{j}} \\lambda_{s} d s\\right]$.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f7107e-508f-4515-97e9-cc8b25babc14",
   "metadata": {},
   "source": [
    "Above formulas give the likelihood function = $\\exp \\left[-\\int_{0}^{t} \\lambda_{s} d s+\\int_{0}^{t} \\log \\lambda_{s} d N_{s}\\right]$ and by considering their quotient we give an intuitive proof of \n",
    "\n",
    "> 3. Suppose that $\\exists P_{0}$ w.r.t. which  $N$  is a stationary Poisson process with rate $1$. Then  $P \\ll P_{0}$ and \n",
    ">\n",
    "> $$ d P /\\left.P_{0}\\right|_{\\mathcal{F}_{t}^{N}}=\\exp \\left[\\int_{0}^{t}\\left(1-\\lambda_{s}\\right) d s+\\int_{0}^{t} \\log \\lambda_{s} d N_{s}\\right] .$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3666f586-2f61-4262-9eb4-fcff8fae344b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Finally we consider the representation of point process martingales. \n",
    "\n",
    "> Let $M_t$ be the innovation martingale and $\\tilde{M}_{t}$ be the uniformly integrable martingale over $\\tilde{\\mathcal{F}}^{N}$, then $\\exists$ predictble $H(t, x)$ s.t. \n",
    ">\n",
    "> $$ \\tilde{M}_{t}=\\tilde{M}_{0}+\\int_{(0, t] \\times E} H(s, x) d M_{s}(d x). $$\n",
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488de556-2d6e-40b7-8f71-e6b9f3310e5c",
   "metadata": {},
   "source": [
    "**Proof.** From properties of stopping time we know that $\\exists$ $V_{n}(u, \\omega) \\in \\mathcal{B}\\left(\\mathbf{R}_{+}\\right) \\times \\tilde{\\mathcal{F}}_{t}^{N}$  s.t. \n",
    "\n",
    "$$\\tilde{M}_{T_{n+1}}(\\omega) 1\\left(T_{n} \\leq t<T_{n+1}\\right) = V_{n}\\left(U_{n+1}(\\omega), \\omega\\right) 1\\left(T_{n} \\leq t<T_{n+1}\\right).$$ \n",
    "\n",
    "Then we give without proof the following construction  \n",
    "\n",
    "$$ H_{t}=V_{n}\\left(t-T_{n}\\right)-\\int_{t-T_{n}}^{\\infty} \\frac{V_{n}(u)}{F_{n}\\left(t-T_{n}, \\infty\\right)} F_{n}(d u), \\quad t \\in\\left(T_{n}, T_{n+1}\\right] $$\n",
    "which is predictable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14699cc-0be6-44ad-811e-2a88341b093d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3. Statistical Framework of Point Processes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b9a4eb-6381-4daa-8c95-49e3f34265b8",
   "metadata": {},
   "source": [
    "> 1. **Observations** or **data** is  represented by sub-$\\sigma$ algebra $\\mathcal{F} \\subset \\mathcal{F}_{\\infty}$. In many cases, $\\mathcal{F} \\subseteq \\sigma(X)$ for some $X$.\n",
    "> \n",
    "> 2. “**Finite sample**” theory concerns observations over a compact set, e.g. $\\mathcal{F}=\\sigma\\left(X_{1}, \\ldots, X_{n}\\right)$; while \"**Asymptotic**\" theory pertains to $\\mathcal{F} \\uparrow \\mathcal{F}_{\\infty}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53146db6-bb84-457e-b076-c938c5da411e",
   "metadata": {},
   "source": [
    "Then we may formalize complete observation and partial observation.\n",
    "\n",
    "> **Model I:** sample space $ = (\\Omega, \\mathcal{G})=(\\mathbf{M}_{p}, \\mathcal{M}_{p})^{n}$ where $N$ is on a compact space $E$ with coordinate mappings $N_{i}(\\omega)=\\omega_{i}$.\n",
    ">\n",
    "> **Model II:** sample space $ = (\\Omega, \\mathcal{G})=(\\mathbf{M}_{p}, \\mathcal{M}_{p})$ where $N$ is on a non-compact space $E$ with  $N(\\omega)=\\omega$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae28459-9e23-4d9d-9613-25ce2ae97089",
   "metadata": {},
   "source": [
    "Partial observation involves restriction to a subset, transformation, etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
