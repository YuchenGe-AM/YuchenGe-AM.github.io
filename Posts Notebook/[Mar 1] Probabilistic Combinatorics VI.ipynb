{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4ecbc3a",
   "metadata": {},
   "source": [
    "## [Mar 1] Probabilistic Combinatorics VII\n",
    "\n",
    "Presenter: Yuchen Ge  \n",
    "Affiliation: University of Oxford  \n",
    "Contact Email: gycdwwd@gmail.com  \n",
    "Website: https://yuchenge-am.github.io\n",
    "\n",
    "### It is six in the morning. The house is asleep. Nice music is playing. I prove and conjecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5f2a81-37b9-435e-8710-90c1034d79c6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 1. More on Phase Transition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8495fc-8d9d-4e7b-933a-9bb54617f827",
   "metadata": {},
   "source": [
    "Call $p=\\frac{1+\\epsilon}{n}$ where $p=\\epsilon=\\lambda n^{-1 / 3}$ the **fine parametrization**. \n",
    "\n",
    "> Let  $C(v)$  denote the component containing a given vertex $v$ with size  $|C(v)|$, and  $C_{i} $ the  $i$-th largest component and  $L_{i}$  its number of vertices.\n",
    "\n",
    "From the symmetry of  $G(n, p)$, the distribution of all  $|C(v)|$  are the same. From $\\operatorname{Pr}\\left[T_{c}^{\\mathrm{po}}=k\\right]=\\lim _{n \\rightarrow \\infty} \\operatorname{Pr}[|C(v)|=k]$ where $T_{c}^{\\mathrm{po}}$ is the minimal $t$ with the Poisson branching model $Y_{t}=0$.\n",
    "\n",
    ">  $$\\operatorname{Pr}[C(v)=k] \\sim \\binom{n}{k-1} k^{k-2} p^{1-k} e^{-c k} \\rightarrow \\frac{e^{-c k}(c k)^{k-1}}{k !}.$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a022d855-62c0-477f-bd22-581c14681ea4",
   "metadata": {},
   "source": [
    "In general, $\\operatorname{Pr}\\left[T_{c}=k\\right] \\sim \\frac{1}{\\sqrt{2 \\pi}} k^{-3 / 2} c^{-1}\\left(c e^{1-c}\\right)^{k}$.  For any  $c \\neq 1$,  $c e^{1-c}<1$  and therefore  $\\operatorname{Pr}\\left[T_{c}=k\\right]$  approaches zero at exponential speed. This gives a bound on the tail distribution:\n",
    "\n",
    "$$\\operatorname{Pr}\\left[\\infty> T_{c} > u\\right]<e^{-u(\\alpha+o(1))}$$\n",
    "\n",
    "where  $\\alpha=c-1-\\ln c>0$. We are particularly interested in the Poisson branching process when  $c$  is near $1$ by setting $c=1+\\epsilon$. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71104dd0-d80e-4522-8a79-62853d98ca22",
   "metadata": {},
   "source": [
    "> $y = \\operatorname{Pr}\\left[T_{1+\\epsilon}=\\infty\\right]$ satisfies $f(y)=1-y-   e^{-(1+\\epsilon) y}=0$, which gives $\\operatorname{Pr}\\left[T_{1+\\epsilon}=\\infty\\right] \\sim 2 \\epsilon$.\n",
    ">\n",
    "> $\\operatorname{Pr}\\left[T_{1+\\epsilon}=u\\right] \\sim \\frac{1}{\\sqrt{2 \\pi}} u^{-3 / 2}$ for $u=o\\left(\\epsilon^{-2}\\right)$ since $\\ln \\left(c e^{1-c}\\right)=\\ln (1+\\epsilon)-\\epsilon \\sim-\\frac{\\epsilon^{2}}{2}$.\n",
    ">\n",
    "> $\\operatorname{Pr}\\left[T_{1+\\epsilon}=A \\epsilon^{-2}\\right] \\sim \\frac{1}{\\sqrt{2 \\pi}} \\epsilon^{3} A^{-3 / 2} e^{-A / 2}$ for  $u=A \\epsilon^{-2}$ where $A$ is fixed.\n",
    ">\n",
    "> $\\operatorname{Pr}\\left[T_{1+\\epsilon}=A \\epsilon^{-2}\\right]=\\epsilon^{3} e^{-(1+o(1)) A / 2}$ for  $u=A \\epsilon^{-2}$ where $\\epsilon \\rightarrow 0^{+}$ and $A \\rightarrow \\infty$.\n",
    ">\n",
    "> $\\operatorname{Pr}\\left[\\infty>T_{1+\\epsilon}>A \\epsilon^{-2}\\right]<e^{-(1+o(1)) A / 2} \\epsilon$ where $\\epsilon \\rightarrow 0^{+}$ and $A \\rightarrow \\infty$.\n",
    "\n",
    "When  $A \\rightarrow \\infty$, $\\operatorname{Pr}\\left[\\infty>T_{1+\\epsilon}>A \\epsilon^{-2}\\right] = o(\\epsilon)$, therefore $\\operatorname{Pr}\\left[T_{1+\\epsilon}>A \\epsilon^{-2}\\right] \\sim 2 \\epsilon \\text { when } \\epsilon \\rightarrow 0^{+} \\text {and } A \\rightarrow \\infty$.\n",
    "\n",
    "The Poisson branching processes with means  $1+\\epsilon$  and  $1-\\epsilon$  look almost the same, with the distinction that the mean  $1+\\epsilon$  process is sometimes infinite while the mean  $1-\\epsilon$  process never is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb04aad-fe94-4ade-bf05-092dcbc9891c",
   "metadata": {},
   "source": [
    "> $\\operatorname{Pr}\\left[T_{1-\\epsilon}>A \\epsilon^{-2}\\right]<e^{-(1+o(1)) A / 2} \\epsilon$ for $\\epsilon \\rightarrow 0^{+}$ and $A \\rightarrow \\infty$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4284138f-08fa-4476-a465-907ee5b59d3d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "In graph branching model, $Y_0=0$, $N_0=n-1$ and $Z_0 = 0$. Then we set $Y_{t}=Y_{t-1}-1+Z_{t}$ and $Z_t$ is found by checking $N_{t−1}$ pairs for adjacency. Therefore, $Z_{t} \\sim B\\left[N_{t-1}, p\\right] \\sim B\\left[n-(t-1)-Y_{t-1}, p\\right]$. Also, set  $N_{t}=N_{t-1}-Z_{t}$, $N_{t} \\sim B\\left[N_{t-1}, 1-p\\right]$. By induction we find the distributions\n",
    "\n",
    "$$N_{t} \\sim B\\left[n-1,(1-p)^{t}\\right] \\text { for } 0 \\leq t \\leq n \\text {. }$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93401791-b6d7-49f2-905e-3f9cc2c35a47",
   "metadata": {},
   "source": [
    "If $T = t$, it is necessary that $N_t= n − t$. Therefore,\n",
    "\n",
    "> $\\operatorname{Pr}[|C(v)|=t] \\leq \\operatorname{Pr}\\left[B\\left[n-1,(1-p)^{t}\\right]=n-t\\right]$.\n",
    ">\n",
    "> $\\operatorname{Pr}\\left[T_{n, p}^{g r} \\geq u\\right] \\leq \\operatorname{Pr}\\left[T_{n-1, p}^{b i n} \\geq u\\right]$ and $\\operatorname{Pr}\\left[T_{n, p}^{g r} \\geq u\\right] \\geq \\operatorname{Pr}\\left[T_{n-u, p}^{b i n} \\geq u\\right]$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da0698b-12c8-484d-a360-9228f462281c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0b936c-fa0f-4951-aa8f-10c93bd76815",
   "metadata": {},
   "source": [
    "Let $p=\\frac{c}{n}$ with $c<1$. Since $\\operatorname{Pr}\\left[T_{n, p}^{\\mathrm{gr}} \\geq u\\right] \\leq \\operatorname{Pr}\\left[T_{n-1, p}^{\\mathrm{bin}} \\geq u\\right]$, with the Poisson approximation below,  $\\operatorname{Pr}[|C(v)| \\geq u] \\leq(1+o(1)) \\operatorname{Pr}\\left[T_{c} \\geq u\\right]$, which drops exponentially in  $u$. Taking  $u=K \\ln n$  for appropriately large  $K$,  $\\operatorname{Pr}[|C(v)| \\geq u]<n^{-1.01}$. As this holds for each of the  $n$  vertices $v$, $\\operatorname{Pr}( \\text{ any  $v$  has  $|C(v)| \\geq u$ } )  < n n^{-1.01} \\rightarrow 0$. That is,  \n",
    "> $L_{1}=O(\\ln n)$  with probability tending to $1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f812c9-1f3c-4203-a6ef-82c143035334",
   "metadata": {},
   "source": [
    "Push the argument into the barely subcritical regime  $p=\\frac{1-\\epsilon}{n}$  with  $\\epsilon=\\lambda n^{-1 / 3}$. Let  $I_{v} = I( \\text{$C(v)$  having at least  $u$  vertices} )$, with  $u$  to be determined below. Poisson approximation gives the bound\n",
    "\n",
    "$$\\operatorname{Pr}[|C(v)| \\geq u] \\leq(1+o(1)) \\operatorname{Pr}\\left[T_{1-\\epsilon} \\geq u\\right]$$\n",
    "\n",
    "Let $u=K \\epsilon^{-2} \\ln \\lambda=K n^{2 / 3} \\lambda^{-2} \\ln \\lambda$. For an appropriately large constant  $K$, the bound gives $\\operatorname{Pr}\\left[T_{1-\\epsilon} \\geq u\\right] \\leq \\epsilon e^{-3.1 \\ln \\lambda}=\\epsilon \\lambda^{-3.1}$.\n",
    "\n",
    "Let  $X=\\sum_{v} I_{v}$ = # vertices  $v$  in components of size $\\geq u$, and $Y$ = #  components of  $G(n, p) $ of size $\\geq u$. Linearity of Expectation gives\n",
    "\n",
    "$$\\mathrm{E}[X]=n \\mathrm{E}\\left[I_{v}\\right] \\leq n \\epsilon \\lambda^{-3.1}=n^{2 / 3} \\lambda^{-2.1}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb753eee-96f5-4ee8-837b-ae229307fb0b",
   "metadata": {},
   "source": [
    "As  $Y \\leq X u^{-1}$, $\\mathrm{E}[Y] \\leq u^{-1} \\mathrm{E}[X] \\leq K^{-1} \\lambda^{-0.1} \\rightarrow 0$.\n",
    "\n",
    "With probability approaching $1$, $Y=0$, and so $L_{1} \\leq u=K \\epsilon^{-2} \\ln \\lambda=K n^{2 / 3} \\lambda^{-2} \\ln \\lambda$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a7d77b-7ab0-4c98-a2ec-06230f07c0be",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24f5558-5f11-45b2-b5af-72acdd3f7972",
   "metadata": {},
   "source": [
    "Start with the very supercritical region, $p=\\frac{c}{n}$, with  $c>1$  constant. The ideas here will carry into the barely supercritical region. (**Details can be seen in P209 of The Probabilistic Method.**)\n",
    "\n",
    "Let  $y=y(c)$  be the positive real solution of the equation  $e^{-c y}=1-y$. Let  $\\delta$  be an arbitrarily small constant, and let  $K$  be an appropriately large constant. Set  $S=K \\ln n$, $L^{-}=(y-\\delta) n$, $L^{+}=(y+\\delta) n$.\n",
    "\n",
    "> Call a component size  $|C(v)|$  small if  $|C(v)|<S$ , giant if  $L^{-}<|C(v)|<   L^{+}$ , awkward otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dca735-65c5-4003-aca9-54e814edc2d9",
   "metadata": {},
   "source": [
    "We claim that \n",
    "\n",
    "> $\\operatorname{Pr}( \\text{have an awkward component} )= o(n^{−20})$. $\\bigg($ bound $\\operatorname{Pr}\\left[B\\left[n-1,1-\\left(1-\\frac{c}{n}\\right)^{t}\\right]=t-1\\right]$ $\\bigg)$\n",
    ">\n",
    "> $\\alpha=\\operatorname{Pr}[C(v) \\text { not small }]\\sim \\operatorname{Pr}\\left[T_{c} \\geq S\\right] \\sim \\operatorname{Pr}\\left[T_{c}=\\infty\\right]=y$. $\\bigg($ sandwich $\\operatorname{Pr}\\left[T_{n-S, p}^{\\mathrm{bin}} \\geq S\\right] \\leq \\alpha \\leq \\operatorname{Pr}\\left[T_{n-1, p}^{\\mathrm{bin}} \\geq S\\right]$ $\\bigg)$\n",
    ">\n",
    "> $\\operatorname{Pr}( \\text{have more than one component} )= o(n^{−20})$. $\\bigg($ coupling and reduce to awkward component $\\bigg)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75db4511-3e85-47d6-a47d-d5badaf9af76",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efcbed9-51c3-4f8d-9b62-3c3635d088e1",
   "metadata": {},
   "source": [
    "### 2. An Approximation Equation\n",
    "\n",
    "Fix $k+m \\leq n$.\n",
    "\n",
    ">  $$\\binom{n-m}{k} p^{k}(1-p)^{n-k}=\\frac{(n p)^{k}}{k !} e^{-n p}\\left(1+\\square\\left(n p^{2}, (k^2+m^2) / n^{-1}\\right)\\right).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ab0ca8-a738-41e0-83a9-880a08e52e45",
   "metadata": {},
   "source": [
    "It suffices that $1-C \\max \\left\\{p^{2} n, (k^{2}+m^2) / n\\right\\} \\leq \\frac{(n-m) !}{(n-m-k) ! n^{k}}(1-p)^{n-k} e^{p n} \\leq 1+C \\max \\left\\{p^{2} n, (k^{2}+m^2) / n\\right\\} $. The middle term achieves its maximum when $p=k/n$ and minimum when $p=0,1$. Therefore, it suffices\n",
    "\n",
    "> $$\\frac{(n-m) !}{(n-m-k) ! n^{k}} \\geq 1-C (k^{2}+m^2) / n, $$\n",
    ">\n",
    "> $$\\frac{(n-m) !}{(n-m-k) ! n^{k}}\\left(1-\\frac{k}{n}\\right)^{n-k} e^{k} \\leq 1+C (k^{2}+m^2) / n, $$\n",
    "\n",
    "and \n",
    "\n",
    "> $$\\frac{(n-m) !}{(n-m-k) ! n^{k}}(1-p)^{n-k} e^{p n} \\geq 1-C p^{2} n \\quad \\text{ for } p \\in [\\frac{\\sqrt{k^2+m^2}}{n}, \\frac{1}{\\sqrt{n}}].$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81afc8e-b6ea-449d-b5a2-99dd087cd7a1",
   "metadata": {},
   "source": [
    "The first is clear. For the second, we've used the fact that \n",
    "\n",
    "$$\\frac{n !}{(n-k) !} \\leq \\frac{n^{n+\\frac{1}{2}}}{(n-k)^{n-k+\\frac{1}{2}}} e^{-k} \\quad \\text{ and } \\quad \\forall x \\geq 0, \\sqrt{1+x} \\leq 1+\\frac{x}{2}.$$\n",
    "\n",
    "Therefore,\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\frac{(n-m) !}{(n-m-k) ! n^{k}}\\left(1-\\frac{k}{n}\\right)^{n-k} e^{k} & \\leq \\frac{n!}{(n-k) ! n^{k}}\\left(1-\\frac{k}{n}\\right)^{n-k} e^{k} \\leq \\frac{n^{n+\\frac{1}{2}} e^{-k}}{(n-k)^{n-k+\\frac{1}{2}} n^{k}} e^{k} \\\\\n",
    "& = \\sqrt{\\frac{n}{n-k}} \\leq 1+\\frac{k}{2(n-k)} \\leq 1+C (k^{2}+m^2) / n.\n",
    "\\end{aligned}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14096066-34fb-4c14-bb4e-92abfa20e5f5",
   "metadata": {},
   "source": [
    "For the third, notice that \n",
    "\n",
    "> $$\\forall p \\in\\left[0, \\frac{1}{\\sqrt{2}}\\right], 1-p \\geq e^{-p-\\sqrt{2} p},$$\n",
    "\n",
    "which follows that\n",
    "\n",
    "$$\\begin{aligned} \\frac{(n-m) !}{(n-m-k) ! n^{k}}(1-p)^{n-k} e^{p n} & \\geq\\left(1-\\frac{k^{2}+m^2}{n}\\right)(1-p)^{n-k} e^{p n} \\geq\\left(1-\\frac{k^{2}+m^2}{n}\\right)\\left(e^{-p-\\sqrt{2} p^{2}}\\right)^{n-k} e^{p n} \\\\\n",
    "& \\geq\\left(1-\\frac{k^{2}+m^2}{n}\\right) e^{-\\sqrt{2} p^{2} n} \\geq\\left(1-\\frac{k^{2}+m^2}{n}\\right)\\left(1-\\sqrt{2} p^{2} n\\right) \\\\\n",
    "& \\geq 1-\\frac{k^{2}+m^2}{n}-\\sqrt{2} p^{2} n  \\geq 1-C p^{2} n.\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e060b4-474f-4461-b519-a971fd646b02",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92502bbf-da12-46e2-b739-c4204fc2c94f",
   "metadata": {},
   "source": [
    "### 3. More on Random Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a7f5ef-c45d-48c8-9198-83ae8020903d",
   "metadata": {},
   "source": [
    "We first study Janson’s inequalities. We consider events $A_i$ of specific types. Consider the random subset  $X_{p}$ of  $X$, and let $ A_{i} =  X_{p} \\supseteq E_{i} \\subseteq X$. \n",
    "\n",
    "> Note that each  $A_{i}$  is an up-set; up-sets of this particular type are called principal upsets. \n",
    "\n",
    "Let  $Z  =$ # $A_{i}$  that hold, and  $\\mu=\\mathbb{E}[Z]=\\sum_{i} \\mathbb{P}\\left(A_{i}\\right)$. Write  $i \\sim j$  if  $i \\neq j$  and  $A_{i}$  and  $A_{j} $ are dependent, i.e., if  $i \\neq j$  and  $E_{i} \\cap E_{j} \\neq \\emptyset$, and let\n",
    "\n",
    "$$\\Delta=\\sum_{i} \\sum_{j \\sim i} \\mathbb{P}\\left(A_{i} \\cap A_{j}\\right).$$\n",
    "\n",
    "> $\\mathbb{P}(Z=0) \\leqslant e^{-\\mu+\\Delta / 2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adddea5-8e2c-421b-90cc-3c3113cc669c",
   "metadata": {},
   "source": [
    "**Proof.** Let  $r_{i}=\\mathbb{P}\\left(A_{i} \\mid A_{1}^{\\mathrm{c}} \\cap \\cdots \\cap A_{i-1}^{\\mathrm{c}}\\right)$. Note that\n",
    "\n",
    "$$\\mathbb{P}(Z=0)=\\mathbb{P}\\left(A_{1}^{\\mathrm{c}} \\cap \\cdots \\cap A_{k}^{\\mathrm{c}}\\right)=\\prod_{i=1}^{k}\\left(1-r_{i}\\right) \\leqslant \\prod_{i=1}^{k} e^{-r_{i}}=\\exp \\left(-\\sum_{i=1}^{k} r_{i}\\right).$$\n",
    "\n",
    "Also by considering $D_{1} = \\cap_{j<i, j \\sim i } A_{j}^{\\mathrm{c}}$ and $D_{0} = \\cap_{j<i, j \\nsim i } A_{j}^{\\mathrm{c}} $, $r_{i} \\geqslant \\mathbb{P}\\left(A_{i}\\right)-\\sum_{j<i, j \\sim i} \\mathbb{P}\\left(A_{i} \\cap A_{j}\\right)$. This shows that \n",
    "\n",
    "$$ \\mathbb{P}(Z=0) \\leqslant \\exp \\left(-\\sum_{i=1}^{k} \\mathbb{P}\\left(A_{i}\\right)+\\sum_{i} \\sum_{j \\sim i, j<i} \\mathbb{P}\\left(A_{i} \\cap A_{j}\\right)\\right) =\\exp (-\\mu+\\Delta / 2) .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe66c4c-c6a4-4028-b806-c82b342165a9",
   "metadata": {},
   "source": [
    "For any  $S \\subseteq[k]$, we have $\\mathbb{P}(Z=0)=\\mathbb{P}\\left(\\bigcap_{i=1}^{k} A_{i}^{\\mathrm{c}}\\right) \\leqslant \\mathbb{P}\\left(\\bigcap_{i \\in S} A_{i}^{\\mathrm{c}}\\right) \\leqslant e^{-\\mu_{S}+\\Delta_{S} / 2}$. Then we randomly choose $S$ with probability $r$, and then \n",
    "\n",
    "$$\\mathbb{E}\\left[\\mu_{S}\\right]=\\sum_{i} r \\mathbb{P}\\left(A_{i}\\right)=r \\mu \\quad \\text{ and } \\quad \\mathbb{E}\\left[\\Delta_{S}\\right]=\\sum_{i} \\sum_{j \\sim i} \\mathbb{P}\\left(A_{i} \\cap A_{j}\\right) \\mathbb{P}(i, j \\in S)=r^{2} \\Delta .$$\n",
    "\n",
    "Thus  $\\mathbb{E}\\left[\\mu_{S}-\\Delta_{S} / 2\\right]=r \\mu-r^{2} \\Delta / 2$, which follows that $\\exists  S$ s.t. $\\mu_{S}-\\Delta_{S} / 2 \\geqslant r \\mu-r^{2} \\Delta / 2$. Therefore,\n",
    "\n",
    "$$ \\mathbb{P}(Z=0) \\leqslant e^{-r \\mu+r^{2} \\Delta / 2} \\implies \\mathbb{P}(Z=0) \\leqslant e^{-\\frac{\\mu^{2}}{\\Delta}+\\frac{\\mu^{2}}{2 \\Delta}}=e^{-\\frac{\\mu^{2}}{2 \\Delta}}$$\n",
    "\n",
    "where we suppose $r=\\mu / \\Delta \\leqslant 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972c075a-6c1e-4b7c-b47e-c374b61ff3ec",
   "metadata": {},
   "source": [
    "> $\\mathbb{P}(Z=0) \\leqslant \\exp \\left(-\\min \\left\\{\\mu / 2, \\mu^{2} /(2 \\Delta)\\right\\}\\right)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d231f3-b1c6-4693-82d4-8c28c7fe9340",
   "metadata": {},
   "source": [
    "For example, When  $\\mu \\geqslant L$  and  $\\mu^{2} / \\Delta \\geqslant L$ , then $\\mathbb{P}(Z=0) \\leqslant e^{-L / 2}$. We shall then use the inequalities to study clique and chromatic number."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6799665c-066a-4bd3-8b49-8e23cad82f7d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Let  $X_{k}$  = \\# copies of  $K_{k}$, and\n",
    "\n",
    "$$\\mu_{k}:=\\mathbb{E}\\left[X_{k}\\right]=\\binom{n}{k} p^{\\binom{k}{2}}$$\n",
    "\n",
    "\n",
    "Note that\n",
    "\n",
    "$$\\frac{\\mu_{k+1}}{\\mu_{k}}=\\binom{n}{k+1}\\binom{n}{k}^{-1} p^{\\binom{k+1}{2}-\\binom{k}{2}}=\\frac{n-k}{k+1} p^{k},$$\n",
    "\n",
    "which is a decreasing function of  $k$, so  $\\mu_{k}$  first increases and then decreases. We define\n",
    "$k_{0}=k_{0}(n, p)=\\min \\left\\{k: \\mu_{k}<1\\right\\}$. Simple computation shows that \n",
    "\n",
    "> With $0<p<1$ fixed, $k_{0} \\sim 2 \\log _{1 / p} n=2 \\frac{\\log n}{\\log (1 / p)}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e0a928-d992-436d-a6a7-8bcae82afb68",
   "metadata": {},
   "source": [
    "Note that if  $k \\sim k_{0}$  then $\\left(\\frac{1}{p}\\right)^{k}=n^{2+o(1)}$ and $\\frac{\\mu_{k+1}}{\\mu_{k}} = n^{-1+o(1)}$. Since $\\mu_{k_{0}+1} \\leqslant n^{-1+o(1)}$, \n",
    "\n",
    "> With  $0<p<1$  fixed, $\\mathbb{P}\\left(\\omega(G(n, p))>k_{0}\\right) \\rightarrow 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1d8495-9e55-463d-b7b5-9473cc2b5008",
   "metadata": {},
   "source": [
    "Let  $\\Delta_{k}$  = expected number of ordered pairs of distinct  $k$-cliques sharing at least one edge.\n",
    "\n",
    "> Suppose that  $k \\sim k_{0}$. Then \n",
    ">\n",
    "> $$\\frac{\\Delta_{k}}{\\mu_{k}^{2}} \\leqslant \\max \\left\\{n^{-2+o(1)}, \\frac{n^{-1+o(1)}}{\\mu_{k}}\\right\\} .$$\n",
    ">\n",
    "> In particular, if  $\\mu_{k} \\rightarrow \\infty$ then  $\\Delta_{k}=o\\left(\\mu_{k}^{2}\\right)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df706ab-dcc6-4d3d-a0a3-84f16bf852b3",
   "metadata": {},
   "source": [
    "Since $\\mu_{k_{0}-1} \\geqslant 1$ and $\\mu_{k_0-2} \\geqslant n^{1-o(1)}$,  \n",
    "\n",
    "> **Thm I.** $\\mathbb{P}\\left(k_{0}-2 \\leqslant \\omega(G) \\leqslant k_{0}\\right) \\rightarrow 1$. \n",
    "\n",
    "Since $\\mu_{k_{0}-3} \\geqslant n^{2-o(1)}$, $\\Delta_{k_0-3} / \\mu_{k_0-3}^{2} \\leqslant n^{-2+o(1)}$ and then $\\mu_{k_0-3}^{2} / \\Delta_{k} \\geqslant n^{2-o(1)}$. By Janson's inequality,\n",
    "\n",
    "> **Thm II.** $\\mathbb{P}\\left(\\omega(G)<k_{0}-3\\right) \\leqslant e^{-n^{2-o(1)}}$ ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7162b289-3ecb-4ac5-87d6-5f2da1fee4c7",
   "metadata": {},
   "source": [
    "This allows us to study the chromatic number, by showing that with high probability every subgraph of a decent size contains a fairly large independent set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94415066-9d47-4869-8926-dfab1f501ff4",
   "metadata": {},
   "source": [
    "> ( **Bollobás** ). Let  $0<p<1$  be fixed and $G=G(n, p)$. Then for any fixed  $\\varepsilon>0$, whp\n",
    ">\n",
    "> $$(1-\\varepsilon) \\frac{n}{2 \\log _{b} n} \\leqslant \\chi(G) \\leqslant(1+\\varepsilon) \\frac{n}{2 \\log _{b} n}$$\n",
    ">\n",
    "> where  $b=1 /(1-p)$.\n",
    "\n",
    "**Proof.** Apply thm I to the complement  $G^{\\mathrm{c}} \\sim G(n, 1-p)$. Then whp  $\\alpha(G)=\\omega\\left(G^{\\mathrm{c}}\\right) \\leqslant   k_{0}(n, 1-p) \\sim 2 \\log _{b} n $. Since  $\\chi(G) \\geqslant n / \\alpha(G)$, this gives the lower bound. Upper bound can also be derived by considering indepedent sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b700c23-abe3-452c-a75d-1892c6e96792",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Reference\n",
    "\n",
    "1. Noga Alon. The Probabilistic Method.\n",
    "2. Ryan O'Donnell. Analysis of Boolean Functions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
