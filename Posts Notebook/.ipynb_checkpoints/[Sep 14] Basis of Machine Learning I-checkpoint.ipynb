{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0980918",
   "metadata": {},
   "source": [
    "## [Sep 14] Basis of Machine Learning I\n",
    "\n",
    "Presenter: Yuchen Ge  \n",
    "Affiliation: University of Oxford  \n",
    "Contact Email: gycdwwd@gmail.com  \n",
    "Website: https://yuchenge-am.github.io"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d290abb1",
   "metadata": {},
   "source": [
    "### Content \n",
    "\n",
    "1. [Basic Definitions](#Basic-Definitions)\n",
    "2. [More General Definitions](#More-General-Definitions)\n",
    "3. [Rademacher Complexity and VC-Dimension](#Rademacher-Complexity-and-VC-Dimension)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed1255a",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a069aa",
   "metadata": {},
   "source": [
    "### 1. Basic Definitions <a id='Basic-Definitions'></a>\n",
    "\n",
    "Some definitions is needed to understand the whole framework. $\\mathcal{X}$ is the set of all possible examples (instances)， and $\\mathcal{Y}$ is the set of all possible labels (target values). For simplicity, $\\mathcal{Y}=\\{ 0,1 \\}$.\n",
    "\n",
    "> **Def 1.**  A **concept** is a mapping $c: \\mathcal{X} \\rightarrow \\mathcal{Y}$.\n",
    "\n",
    "A concept class is a set of concepts we may wish to learn, which is denoted by $\\mathcal{C}$. All concepts that we consider form a hypothesis set, which is denoted by $\\mathcal{H}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f642983e",
   "metadata": {},
   "source": [
    "When we learn some $c \\in \\mathcal{C}$, we receive a sample $S=\\left(x_{1}, \\ldots, x_{m}\\right)$ drawn i.i.d. according to $\\mathcal{I}$.\n",
    "\n",
    "The ultimate goal is to minimize \n",
    "\n",
    "> **Def 2.** (Generalization error) The generalization error (risk) of  $h\\in\\mathcal{H}$  is defined by\n",
    ">\n",
    ">$$R(h)=\\underset{x \\sim \\mathcal{D}}{\\mathbb{P}}[h(x) \\neq c(x)]=\\underset{x \\sim \\mathcal{D}}{\\mathbb{E}}\\left[1_{h(x) \\neq c(x)}\\right].$$\n",
    "\n",
    "Also, we may have the emprical error \n",
    "\n",
    "$$\\widehat{R}_{S}(h)=\\frac{1}{m} \\sum_{i=1}^{m} 1_{h\\left(x_{i}\\right) \\neq c\\left(x_{i}\\right)}.$$\n",
    "\n",
    "We will see in the following a number of guarantees relating these two quantities with high probability, under some general assumptions.\n",
    "\n",
    "> **Remark:** this reminds me of the definition of a sourcr code $C$ in information theory, which is a mapping from $\\mathcal{X}$, the range of a random variable $X$, to $D^{∗}$, the set of finite-length strings of symbols from a $D$-ary alphabet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f48685",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0daae93",
   "metadata": {},
   "source": [
    "The following introduces the Probably Approximately Correct (PAC) learning framework, where the concept $h_S$ is selected based on the algorithm $\\mathcal{A}$ and the sample $S$.\n",
    "\n",
    "> **Def 3.** (PAC-learning)  $\\mathcal{C}$  is PAC-learnable if there exists an algorithm  $\\mathcal{A}$  and a polynomial function poly  $(\\cdot, \\cdot, \\cdot, \\cdot)$  such that for any  $\\epsilon>0$  and  $\\delta>0$, the following holds for any distribution $\\mathcal{D}$, the goal $c\\in \\mathcal{C}$, and the sample size  $m \\geq \\operatorname{poly}(1 / \\epsilon, 1 / \\delta, n , size  (c))$:\n",
    ">\n",
    ">$$\\underset{S \\sim \\mathcal{D}^{m}}{\\mathbb{P}}\\left[R\\left(h_{S}\\right) \\leq \\epsilon\\right] \\geq 1-\\delta.$$\n",
    "\n",
    "When $\\# \\mathcal{H}<\\infty$, we know that \n",
    "\n",
    "> **Thm 1.** ( $\\# \\mathcal{H}<\\infty$, consistent )  When the algorithm  $\\mathcal{A}$ is s.t. for any goal $c\\in\\mathcal{H}$, $\\widehat{R}_{S}\\left(h_{S}\\right)=0$. Then  for any $\\epsilon, \\delta>0$, the inequality\n",
    ">\n",
    "> $$\\underset{S \\sim \\mathcal{D}^{m}}{\\mathbb{P}}\\left[R\\left(h_{S}\\right) \\leq \\epsilon\\right] \\geq 1-\\delta$$  holds if\n",
    "> $$ m \\geq \\frac{1}{\\epsilon}\\left(\\log \\#\\mathcal{H}+\\log \\frac{1}{\\delta}\\right).$$\n",
    "\n",
    "**Proof.** Define $\\mathcal{H}_{\\epsilon}=\\{h \\in \\mathcal{H}: R(h)>\\epsilon\\}$. Then $\n",
    "\\mathbb{P}[\\widehat{R}_{S}(h)=0] \\leq(1-\\epsilon)^{m}$ for $h\\in\\mathcal{H}_{\\epsilon}$, since $R(h)=\\underset{x \\sim \\mathcal{D}}{\\mathbb{P}}[h(x) \\neq c(x)]>\\epsilon$. Thus, by the union bound, the following holds:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\mathbb{P}\\left[\\exists h \\in \\mathcal{H}_{\\epsilon}: \\widehat{R}_{S}(h)=0\\right] & =\\mathbb{P}\\left[\\widehat{R}_{S}\\left(h_{1}\\right)=0 \\vee \\cdots \\vee \\widehat{R}_{S}\\left(h_{\\#\\mathcal{H}_{\\epsilon}}\\right)=0\\right]\\\\\n",
    "& \\leq \\sum_{h \\in \\mathcal{H}_{\\epsilon}} \\mathbb{P}\\left[\\widehat{R}_{S}(h)=0\\right] \\\\\n",
    "& \\leq \\sum_{h \\in \\mathcal{H}_{\\epsilon}}(1-\\epsilon)^{m} \\leq|\\mathcal{H}|(1-\\epsilon)^{m} \\leq|\\mathcal{H}| e^{-m \\epsilon} .\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d56c78",
   "metadata": {},
   "source": [
    "Equivalently, in the language of generalization bound, with probability at least $1-\\delta$, $R(h_{S}) \\leq \\frac{1}{m}(\\log \\#\\mathcal{H}+\\log \\frac{1}{\\delta})$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767df899",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> **Lemma 1.** (Hoeffding's inequality) Let  $X_{1}, \\ldots, X_{m}$  be independent random variables with  $X_{i}\\in \\left[a_{i}, b_{i}\\right]$  for all  $i \\in[m]$. Then, for any  $\\epsilon>0$,\n",
    ">\n",
    ">$$\\begin{aligned}\n",
    "& \\mathbb{P}\\left[S_{m}-\\mathbb{E}\\left[S_{m}\\right] \\geq \\epsilon\\right] \\leq e^{-2 \\epsilon^{2} / \\sum_{i=1}^{m}\\left(b_{i}-a_{i}\\right)^{2}}, \\\\\n",
    "& \\mathbb{P}\\left[S_{m}-\\mathbb{E}\\left[S_{m}\\right] \\leq-\\epsilon\\right] \\leq e^{-2 \\epsilon^{2} / \\sum_{i=1}^{m}\\left(b_{i}-a_{i}\\right)^{2}}. \\end{aligned} $$\n",
    "\n",
    "Through **lemma 1**, we can derive\n",
    "\n",
    "> **Thm 1.** ( $\\# \\mathcal{H}<\\infty$, inconsistent )  For any $h\\in \\mathcal{H}$, with probability at least $1-\\delta$, \n",
    ">\n",
    ">$$ R(h) \\leq \\widehat{R}_{S}(h)+\\sqrt{\\frac{\\log \\# \\mathcal{H}+\\log \\frac{2}{\\delta}}{2 m}}.$$\n",
    "\n",
    "Before proof, this can be viewed as an instance of the so-called **Occam’s Razor principle**: All other things being equal, a simpler (smaller) hypothesis set is better.\n",
    "\n",
    "**Proof.** Seeing that \n",
    "$$\\begin{aligned}\n",
    "& \\mathbb{P}\\left[\\exists h \\in \\mathcal{H}: \\left|\\widehat{R}_{S}(h)-R(h)\\right|>\\epsilon\\right] \\\\\n",
    "= \\text{ } & \\mathbb{P}\\left[\\left(\\left|\\widehat{R}_{S}\\left(h_{1}\\right) R\\left(h_{1}\\right)\\right|>\\epsilon\\right) \\vee \\ldots \\vee\\left(\\left|\\widehat{R}_{S}\\left(h_{\\#\\mathcal{H}}\\right)-R\\left(h_{\\#\\mathcal{H}}\\right)\\right|>\\epsilon\\right)\\right] \\\\\n",
    "\\leq \\text{ } & \\sum_{h \\in \\mathcal{H}} \\mathbb{P}\\left[\\left|\\widehat{R}_{S}(h)-R(h)\\right|>\\epsilon\\right] \\\\\n",
    "\\leq \\text{ } & 2 \\#\\mathcal{H} \\cdot \\exp \\left(-2 m \\epsilon^{2}\\right) .\n",
    "\\end{aligned}$$\n",
    "\n",
    "where the last inequality applies **lemma 1**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff4ef57",
   "metadata": {},
   "source": [
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5461653e",
   "metadata": {},
   "source": [
    "### 2. More General Definitions <a id='More-General-Definitions'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9def08a7",
   "metadata": {},
   "source": [
    "In the most general scenario of supervised learning, we consider a distribution $\\mathcal{D}$ over $\\mathcal{X} \\times \\mathcal{Y}$, i.e. the stochastic scenario. Then, we define \n",
    "\n",
    "> $$R(h)=\\underset{(x, y) \\sim \\mathcal{D}}{\\mathbb{P}}[h(x) \\neq y]=\\underset{(x, y) \\sim \\mathcal{D}}{\\mathbb{E}}\\left[1_{h(x) \\neq y}\\right]$$\n",
    "\n",
    "and the Bayesian error\n",
    "\n",
    "> $$R^{\\star}=\\inf _{h \\text { measurable }} R(h).$$\n",
    "\n",
    "Immediately, we can write \n",
    "\n",
    "$$R(h)-R^{*}=\\left(R(h)-\\inf _{h \\in \\mathcal{H}} R(h)\\right)+\\left(\\inf _{h \\in \\mathcal{H}} R(h)-R^{*}\\right),$$\n",
    "\n",
    "where the first term is called the **estimation error**, the second term the **approximation error**. Model selection consists of choosing $\\mathcal{H}$ with a favorable trade-off between the approximation and estimation errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3fa578",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4c4d76",
   "metadata": {},
   "source": [
    "### 3. Rademacher Complexity and VC-Dimension <a id='Rademacher-Complexity-and-VC-Dimension'></a>\n",
    "\n",
    "Let $\\mathcal{G}=\\{g:(x, y) \\mapsto L(h(x), y): h \\in \\mathcal{H}\\}$ be the family of loss functions associated to $\\mathcal{H}$.\n",
    "\n",
    "> ( Empirical Rademacher complexity ) Let $S = (z_1,...,z_m)$ be a fixed sample of size $m$ with elements in $\\mathcal{Z} = \\mathcal{X} \\times \\mathcal{Y}$.\n",
    "> $$\\widehat{\\mathfrak{R}}_{S}(\\mathcal{G})=\\underset{\\boldsymbol{\\sigma}}{\\mathbb{E}}\\left[\\sup _{g \\in \\mathcal{G}} \\frac{\\boldsymbol{\\sigma} \\cdot \\mathbf{g}_{S}}{m}\\right],$$\n",
    "> where $\\sigma = (\\sigma_1, . . . , \\sigma_m)^{T}$, with $\\sigma$'s independent uniform random variables taking\n",
    "values in {−1,+1}.\n",
    "\n",
    "The empirical Rademacher complexity measures on average how well the function class $\\mathcal{G}$ correlates with random noise $\\sigma$ on $S$. Furthermore, the general Rademacher complexity is defined as $\\mathfrak{R}_{m}(\\mathcal{G})=\\underset{S \\sim \\mathcal{D}^{m}}{\\mathbb{E}}\\left[\\widehat{\\Re}_{S}(\\mathcal{G})\\right]$.\n",
    "\n",
    "The Rademacher complexity can be bounded in terms of the growth function.\n",
    "\n",
    "> ( Growth Function ) The growth function  $\\Pi_{\\mathcal{H}}: \\mathbb{N} \\rightarrow \\mathbb{N}$  for a hypothesis set  $\\mathcal{H}$  is defined by:\n",
    ">\n",
    "> $$\\forall m \\in \\mathbb{N}, \\Pi_{\\mathcal{H}}(m)=\\max _{\\left\\{x_{1}, \\ldots, x_{m}\\right\\} \\subseteq X}\\left|\\left\\{\\left(h\\left(x_{1}\\right), \\ldots, h\\left(x_{m}\\right)\\right): h \\in \\mathcal{H}\\right\\}\\right|.$$\n",
    "\n",
    "In other words, $\\Pi_{\\mathcal{H}}$ counts the maximal number of distinct ways of classifying $m$ points with the hypothesis set $\\mathcal{H}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16ae2f1",
   "metadata": {},
   "source": [
    "Employing the following lemma:\n",
    "\n",
    "> ( Maximal Inequality ) Let  $X_{1} \\ldots X_{n}$  be real-valued random variables such that for all  $j \\in[n], X_{j}=\\sum_{i=1}^{m} Y_{i j}$  where, for each fixed  $j \\in[n]$, $Y_{i j}$  are independent zero mean random variables taking values in  $\\left[-r_{ij},+r_{ij}\\right]$, for some  $r_{ij} \\geq 0$. Then, the following inequality holds:\n",
    ">\n",
    ">$$\\mathbb{E}\\left[\\max _{j \\in[n]} X_{j}\\right] \\leq r \\sqrt{2 \\log n},$$\n",
    "> with $r= \\max_{j} \\sqrt{\\sum_{i=1}^{m} r_{ij}^{2}}.$\n",
    "\n",
    "And we have \n",
    "\n",
    "> ( **Massart's Lemma** ) Let  $\\mathcal{A} \\subseteq \\mathbb{R}^{m}$  be a finite set, with  $r=\\max _{\\mathbf{x} \\in \\mathcal{A}}\\|\\mathbf{x}\\|_{2}$, then the following holds:\n",
    ">\n",
    "> $$\\underset{\\boldsymbol{\\sigma}}{\\mathbb{E}}\\left[\\frac{1}{m} \\sup _{\\mathbf{x} \\in \\mathcal{A}} \\sum_{i=1}^{m} \\sigma_{i} x_{i}\\right] \\leq \\frac{r \\sqrt{2 \\log |\\mathcal{A}|}}{m},$$\n",
    "> where  $\\sigma_{i}$'s  are independent uniform random variables taking values in  $\\{-1,+1\\}$  and $ x_{1}, \\ldots, x_{m}$  are the components of vector  $\\mathbf{x}$.\n",
    "\n",
    "With the famous **Massart's lemma**, we can bound the Rademacher complexity with the growth function in an obvious way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83b1aec",
   "metadata": {},
   "source": [
    "Finally, we define the VC-dimension:\n",
    "\n",
    ">  ( **VC-dimension** ) $\\operatorname{VCdim}(\\mathcal{H})=\\max \\left\\{m: \\Pi_{\\mathcal{H}}(m)=2^{m}\\right\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cfd6e6",
   "metadata": {},
   "source": [
    "### Reference\n",
    "\n",
    "1. Mohri, M., Rostamizadeh, A., &amp; Talwalkar, A. (2018). Foundations of Machine Learning. The MIT Press. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
