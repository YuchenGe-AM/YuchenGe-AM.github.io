{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4ecbc3a",
   "metadata": {},
   "source": [
    "## [Nov 28] Probabilistic Combinatorics I\n",
    "\n",
    "Presenter: Yuchen Ge  \n",
    "Affiliation: University of Oxford  \n",
    "Contact Email: gycdwwd@gmail.com  \n",
    "Website: https://yuchenge-am.github.io"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f716c726",
   "metadata": {},
   "source": [
    "### What you need is that your brain is open. \n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc6b152-e98d-4554-b80a-12d53afacbaf",
   "metadata": {},
   "source": [
    "### 1. Ramsey Number \n",
    "\n",
    "We shall give a sketch of how probabilsitic methods can be applied. Recall that  $R(k, l)>n$  means $\\exists$ a two-coloring of the edges of $ K_{n} $ by two colours so that there is neither a monochromatic  $K_{k}$  or $K_{l}$.\n",
    "\n",
    "> **Thm I.** If $\\left(\\begin{array}{l} n \\\\ k \\end{array}\\right) \\cdot 2^{1-\\left(\\begin{array}{l} k \\\\ 2 \\end{array}\\right)}<1$, then $R(k, k)>n$.\n",
    "\n",
    "**Proof.** Consider a random two-coloring of the edges of  $K_{n}$. Fix set  $R$  of  $k$  vertices, let $A_{R}$ be the event that the induced subgraph of  $K_{n}$ on  $R$  is monochromatic. Clearly, $\\mathbb{P}\\left[A_{R}\\right]=2^{1-\\left(\\begin{array}{l}k \\\\ 2\\end{array}\\right)}$, which follows that $\\mathbb{P}(\\bigvee_{R} A_{R}) \\leq  \\left(\\begin{array}{l}n \\\\ k\\end{array}\\right) 2^{1-\\left(\\begin{array}{l}k \\\\ 2\\end{array}\\right)}<1$.\n",
    "\n",
    "If we let  $X_{R}$  be the indicator random variable for $A_R$. Set  $X=\\sum X_{R}$, and we have \n",
    "\n",
    "$$ \\mathrm{E}[X]=\\sum \\mathrm{E}\\left[X_{R}\\right]=\\left(\\begin{array}{l} n \\\\ k \\end{array}\\right) 2^{1-\\left(\\begin{array}{l} k \\\\ 2 \\end{array}\\right)} =m$$\n",
    "\n",
    "Thus there exists a two-coloring for which  $X \\leq m$. Fix such a coloring. Remove from  $K_{n}$  one vertex from each monochromatic $k$-set. At most  $m$  vertices have been removed, so  $s$  vertices remain with  $s \\geq n-m$. This coloring on these $s$  points has no monochromatic  $k$-set. Therefore, \n",
    "\n",
    "$$ R(k, k)>n-\\left(\\begin{array}{l} n \\\\ k \\end{array}\\right) 2^{1-\\left(\\begin{array}{l} k \\\\ 2 \\end{array}\\right)}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25d9503-491b-459d-8b9e-59de13253c20",
   "metadata": {},
   "source": [
    "### 2. Tournament \n",
    "\n",
    "> **Thm I.** If  $\\left(\\begin{array}{l}n \\\\ k\\end{array}\\right)\\left(1-2^{-k}\\right)^{n-k}<1$, then there is a tournament $T$ on  $K_n$ s.t. $S_{k}$ holds. ( a tournament $T$ is an orientation of the edges of $K_n$ : $T$ has the property $S_k$ if $\\forall$ k Players, there is one that beats them all )\n",
    ">\n",
    "> **Thm II.** $\\exists$ a tournament  $T$  with  $n$  players and at least  $n ! 2^{-(n-1)}$  Hamiltonian paths.\n",
    "\n",
    "**Proof.** For the first, consider a random tournament on $[n]$. Let  $A_{K}$  be the event that there is no vertex that beats all the members of  $K$. Clearly, $ \\mathbb{P}\\left[A_{K}\\right]=\\left(1-2^{-k}\\right)^{n-k}$, which follows the conclusion. For the second, in the random tournament let  $X$  be the number of Hamiltonian paths. For each permutation  $\\sigma$, let  $X_{\\sigma}$  be the indicator random variable for  $\\sigma$  giving a Hamiltonian path, that is, satisfying  $(\\sigma(i), \\sigma(i+1)) \\in T $ for $ 1 \\leq i<n$ . Then  \n",
    "\n",
    "$$X=\\sum X_{\\sigma}  \\implies \\mathrm{E}[X]=\\sum \\mathrm{E}\\left[X_{\\sigma}\\right]=n ! 2^{-(n-1)}.$$\n",
    "\n",
    "Thus some tournament has at least  $\\mathrm{E}[X]$  Hamiltonian paths.\n",
    "\n",
    "Actually, **Szele** conjectured that the number of Hamiltonian paths is at most this number and this is true."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0ba3d3-87be-403e-bd2c-731276d41f45",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 3. Erdos–Ko–Rado Theorem ( New Proof )\n",
    "\n",
    "Recall that \n",
    "\n",
    "> Assume $n \\geq 2 k$, and let  $\\mathcal{F}$  be an intersecting family of  $k$-element subsets of $[n]$, the **Erdós-Ko-Rado theorem** states that  $|\\mathcal{F}| \\leq\\left(\\begin{array}{l}n-1 \\\\ k-1\\end{array}\\right)$. \n",
    "\n",
    "We may give a short proof due to Katona (1972).\n",
    "\n",
    "**Proof.** Directly observe that \n",
    "\n",
    "> **Lemma.** For  $s \\in [n]$, set  $A_{s}=\\{s, s+1, \\ldots, s+k-1\\}$, where addition is modulo $n$. Then  $\\mathcal{F}$  can contain at most  $k$  of the sets  $A_{s}$.\n",
    "\n",
    "Let a permutation  $\\sigma$  of  $[n]$  and  $i \\in [n]$  be chosen randomly, uniformly and independently and set  $A=\\{\\sigma(i), \\sigma(i+1), \\ldots, \\sigma(i+k-1)\\}$, addition modulo  $n$. Conditioning on any choice of $\\sigma$, the lemma gives  $\\mathbb{P}[A \\in \\mathcal{F}] \\leq k / n$. Hence  $\\mathbb{P}[A \\in \\mathcal{F}] \\leq k / n$. But  $A$  is uniformly chosen from all  $k$-sets so\n",
    "\n",
    "$$\\frac{k}{n} \\geq \\mathbb{P}[A \\in \\mathcal{F}]=\\frac{|\\mathcal{F}|}{\\left(\\begin{array}{l} n \\\\ k \\end{array}\\right)} \\implies |\\mathcal{F}| \\leq \\frac{k}{n}\\left(\\begin{array}{l} n \\\\ k \\end{array}\\right)=\\left(\\begin{array}{l} n-1 \\\\ k-1 \\end{array}\\right).$$ \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c1b72c-a3cf-4c5f-bf48-f46532eacf81",
   "metadata": {},
   "source": [
    "### 4. Balancing Vectors\n",
    "\n",
    "> **Prop I.** Let  $v_{1}, \\ldots, v_{n} \\in R^{n}$, all  $\\left|v_{i}\\right|=1$. Then $\\exists$  $\\epsilon_{1}, \\ldots, \\epsilon_{n}= \\pm 1$  s.t. $\\left|\\epsilon_{1} v_{1}+\\cdots+\\epsilon_{n} v_{n}\\right| \\leq (\\geq) \\sqrt{n}$.\n",
    ">\n",
    "> **Prop II.** Let  $v_{1}, \\ldots, v_{n} \\in R^{n}$, all  $\\left|v_{i}\\right| \\leq 1$. Let  $p_{1}, \\ldots, p_{n} \\in[0,1]$  be arbitrary, and set  $w=p_{1} v_{1}+\\cdots+p_{n} v_{n}$. Then $\\exists$  $\\epsilon_{1}, \\ldots, \\epsilon_{n} \\in\\{0,1\\}$  s.t.  $|w-v| \\leq \\frac{\\sqrt{n}}{2}$ where $v=\\epsilon_{1} v_{1}+\\cdots+\\epsilon_{n} v_{n}$.\n",
    "\n",
    "\n",
    "**Proof.** We only prove the first, the second can be proved similarly. Let  $\\epsilon_{1}, \\ldots, \\epsilon_{n}$  be selected uniformly and independently from  $\\{-1,+1\\}$. Set $X=\\left|\\epsilon_{1} v_{1}+\\cdots+\\epsilon_{n} v_{n}\\right|^{2}$. Then\n",
    "\n",
    "$$ X=\\sum_{i=1}^{n} \\sum_{j=1}^{n} \\epsilon_{i} \\epsilon_{j} v_{i} \\cdot v_{j} \\implies \\mathrm{E}[X]=\\sum_{i=1}^{n} \\sum_{j=1}^{n} v_{i} \\cdot v_{j} \\mathrm{E}\\left[\\epsilon_{i} \\epsilon_{j}\\right] = \\sum_{i=1}^{n} v_{i} \\cdot v_{i} = n.$$ \n",
    "\n",
    "\n",
    "> **Thm I.** Let  $a_{i j}= \\pm 1$. Then $\\exists  x_{i}, y_{j}= \\pm 1,1 \\leq i, j \\leq n$  s.t. $\\sum_{i=1}^{n} \\sum_{j=1}^{n} a_{i j} x_{i} y_{j} \\geq\\left(\\sqrt{\\frac{2}{\\pi}}+o(1)\\right) n^{3 / 2}$.\n",
    "\n",
    "\n",
    "**Proof.** Forget the  $x$'s. Let  $y_{1}, \\ldots, y_{n}= \\pm 1$  be selected independently and uniformly and set $R_{i}=\\sum_{j=1}^{n} a_{i j} y_{j}, R=\\sum_{i=1}^{n}\\left|R_{i}\\right|$. $a_{i j} y_{j}$  is $\\pm 1$ with probability  $1 / 2$, and their values ( over  $j$  ) are independent. Thus  $R_{i} $ has distribution  $S_{n}$ and so\n",
    "\n",
    "$$\\mathrm{E}\\left[\\left|R_{i}\\right|\\right]=\\mathrm{E}\\left[\\left|S_{n}\\right|\\right]=\\left(\\sqrt{\\frac{2}{\\pi}}+o(1)\\right) \\sqrt{n} .$$\n",
    "\n",
    "\n",
    "These asymptotics may be found by estimating  $S_{n}$  by $ \\sqrt{n} N$, where  $N=N(0,1)$. Now since $\\mathrm{E}[R]=\\sum_{i=1}^{n} \\mathrm{E}\\left[\\left|R_{i}\\right|\\right]=\\left(\\sqrt{\\frac{2}{\\pi}}+o(1)\\right) n^{3 / 2}$, there exist  $y_{1}, \\ldots, y_{n}= \\pm 1$  with  $R$  at least this value. Finally, pick $ x_{i}$  with the same sign as  $R_{i}$  s.t.\n",
    "\n",
    "$$\\sum_{i=1}^{n} x_{i} \\sum_{j=1}^{n} a_{i j} y_{j}=\\sum_{i=1}^{n} x_{i} R_{i}=\\sum_{i=1}^{n}\\left|R_{i}\\right|=R \\geq\\left(\\sqrt{\\frac{2}{\\pi}}+o(1)\\right) n^{3 / 2}.$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e263e6-b5fc-433a-b30c-e590140d5b56",
   "metadata": {},
   "source": [
    "### 5. Existence Problems for Bipartite Subgraphs and Independent Sets\n",
    "\n",
    "> **Thm.** $G=(V, E)$ has $n$  vertices and $e$ edges. Then  $G$  contains a bipartite subgraph with at least $e/2$ edges.\n",
    ">\n",
    "> **Cor.** If $|V|=2n$ and $|E|=e$, Then  $G$  contains a bipartite subgraph with at least $en/(2n-1)$ edges. If $|V|=2n+1$ and $|E|=e$, Then  $G$  contains a bipartite subgraph with at least $e(n+1)/(2n+1)$ edges.\n",
    "\n",
    "Proof. Let  $T \\subseteq V$  be a random subset given by  $\\operatorname{Pr}[x \\in T]=1 / 2$, these choices being mutually independent. Set  $B=V-T$. Call an edge  $\\{x, y\\}$ **crossing** if exactly one of  $x, y$  is in  $T$. Let  $X$  be the number of crossing edges, which follows that $X=\\sum_{\\{x, y\\} \\in E} X_{x y}$ where  $X_{x y}$  is the indicator random variable for  $\\{x, y\\}$  being crossing. Then \n",
    "\n",
    "$$\\mathrm{E}\\left[X_{x y}\\right]=\\frac{1}{2} \\implies \\mathrm{E}[X]=\\sum_{\\{x, y\\} \\in E} \\mathrm{E}\\left[X_{x y}\\right]=\\frac{e}{2}.$$ \n",
    "\n",
    "Thus  $X \\geq e / 2$  for some choice of  $T$, and the set of those crossing edges forms a bipartite graph. A more subtle probability space gives the corollary. For example, let $T$ be chosen uniformly from among all $n$-element subsets of $V$.\n",
    "\n",
    "\n",
    "> **Thm.** $G=(V, E)$  has  $n$  vertices and  $n d / 2$  edges,  $d \\geq 1$. Then  $\\alpha(G) \\geq n / 2 d$.\n",
    "\n",
    "Proof. Let  $S \\subseteq V$  be a random subset defined by $\\operatorname{Pr}[v \\in S]=p$, and the events  $v \\in S$  being mutually independent. Let  $X=|S|$, and let  $Y $ be the number of edges in  $\\left.G\\right|_{S}$. For each  $e=\\{i, j\\} \\in E$, let  $Y_{e}$  be the indicator random variable for the event  $i, j \\in S$  s.t.  $Y=\\sum_{e \\in E} Y_{e}$. Then,\n",
    "\n",
    "$$\\mathrm{E}\\left[Y_{e}\\right]=\\operatorname{Pr}[i, j \\in S]=p^{2} \\implies \\mathrm{E}[Y]=\\sum_{e \\in E} \\mathrm{E}\\left[Y_{e}\\right]=\\frac{n d}{2} p^{2}. $$\n",
    "\n",
    "Clearly,  $\\mathrm{E}[X]=n p \\implies \\mathrm{E}[X-Y]=n p-\\frac{n d}{2} p^{2}$. We set  $p=1 / d$  (here using  $d \\geq 1$  ) to maximize this quantity, giving $\\mathrm{E}[X-Y]=\\frac{n}{2 d}$.\n",
    "\n",
    "\n",
    "Thus there exists a specific $S$  for which the number of vertices of  $S$  minus the number of edges in  $S$  is at least  $n / 2 d$. Select one vertex from each edge of  $S$  and delete it. This leaves a set  $S^{*}$  with at least  $n / 2 d$  vertices which is an independent set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f45a5b-0b37-4737-9de4-40c658375d95",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33d22a9-94c5-4bd6-9df0-2d493eacc3d6",
   "metadata": {},
   "source": [
    "### 6. Boolean Functions\n",
    "\n",
    "A Boolean function $f:\\mathbb{F}_2^{n} \\rightarrow \\mathbb{F}_2$ maps astring into a bit. Most frequently, we shall adopt the form $ f:\\{-1,1\\}^{n} \\rightarrow\\{-1,1\\} $.\n",
    "\n",
    "> Every function  $f:\\{-1,1\\}^{n} \\rightarrow \\mathbb{R}$  can be uniquely expressed as $f(x)=\\sum_{S \\subseteq[n]} \\widehat{f}(S) x^{S} = \\sum_{S \\subseteq[n]} \\widehat{f}(S) \\chi_{S}$. ( in words, any $f$ can be represented as a linear combination of logical parity functions $\\chi_{S}:\\{-1,1\\}^{n} \\rightarrow \\{-1,1\\}$ )\n",
    "\n",
    "**Proof.** Note that for $a=\\left(a_{1}, \\ldots, a_{n}\\right) \\in\\{-1,1\\}^{n}$, the indicator polynomial is $1_{\\{a\\}}(x)=\\left(\\frac{1+a_{1} x_{1}}{2}\\right)\\left(\\frac{1+a_{2} x_{2}}{2}\\right) \\cdots\\left(\\frac{1+a_{n} x_{n}}{2}\\right)$ and $x_i^k=x_i$ on ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ff0538-505d-42a0-b747-52625894f917",
   "metadata": {},
   "source": [
    "Next we shall assume that $f:\\{-1,1\\}^{n} \\rightarrow \\mathbb{R}$. Then we define $\\langle f, g\\rangle = \\underset{x \\sim\\{-1,1\\}^{n}}{\\mathbf{E}}[f(x) g(x)] = 2^{-n} \\sum_{x \\in\\{-1,1\\}^{n}} f(x) g(x)$.\n",
    "\n",
    "> **Prop I.** $\\chi_{S}(x) \\chi_{T}(x)=\\chi_{S \\triangle T}(x)$.\n",
    ">\n",
    "> **Prop II.** From Prop I, we have $$\\mathbf{E}\\left[\\chi_{S}(\\boldsymbol{x})\\right]=\\mathbf{E}\\left[\\prod_{i \\in S} \\boldsymbol{x}_{i}\\right]=\\left\\{\\begin{array}{ll}1 & \\text { if } S=\\varnothing \\\\ 0 & \\text { if } S \\neq \\varnothing\\end{array}\\right. \\implies \\left\\langle\\chi_{S}, \\chi_{T}\\right\\rangle=\\left\\{\\begin{array}{ll}\n",
    "1 & \\text { if } S=T \\\\ 0 & \\text { if } S \\neq T \\end{array}\\right. .$$\n",
    "\n",
    "It follows from the propositions that we have $\\langle f, f\\rangle=\\underset{\\boldsymbol{x} \\sim\\{-1,1]^{n}}{\\mathbf{E}}\\left[f(\\boldsymbol{x})^{2}\\right]=\\sum_{S \\subseteq[n]} \\widehat{f}(S)^{2}$ ( **Parseval’s Theorem** ) and $\\langle f, g\\rangle=\\underset{x \\sim\\{-1,1\\}^{n}}{\\mathbf{E}}[f(x) g(x)]=\\sum_{S \\subseteq[n]} \\widehat{f}(S) \\widehat{g}(S)$ ( **Plancherel’s Theorem** ). The expectation and variation is naturally defined and has the following property:\n",
    "\n",
    "> **Prop I.** $\\mathbf{E}[f]=\\langle f, 1\\rangle=\\widehat{ f} (\\varnothing)$. Moreover if $f\\in\\{-1,1\\}$, then $\\mathbf{E}[f]=\\mathbb{P }(f=1)-\\mathbb{P}(f=-1)$.\n",
    ">\n",
    "> **Prop II.** $\\operatorname{Var}[f] =\\mathbf{E}\\left[f^{2}\\right]-\\mathbf{E}[f]^{2}=\\sum_{S \\neq \\varnothing} \\widehat{f}(S)^{2}$\n",
    "\n",
    "The (Fourier) weight of  $f:\\{-1,1\\}^{n} \\rightarrow \\mathbb{R}$  on set  $S$  is the squared Fourier coefficient, $\\widehat{f}(S)^{2}$. If $f\\in\\{-1,1\\}$, then the **spectral sample** for  $f$, denoted  $S_{f}$, is the probability distribution on $\\mathcal{P} [n]$  in which the set  $S$  has probability  $\\widehat{f}(S)^{2}$. We write  $\\boldsymbol{S} \\sim \\mathcal{S}_{f}$  for a draw from this distribution.\n",
    "\n",
    "Next we use $\\mathbb{F}_2^{n}$ instead of $\\{-1,1\\}^{n}$. For  $S \\subseteq[n]$  we define  $\\chi_{S}: \\mathbb{F}_{2}^{n} \\rightarrow \\mathbb{R}$  by\n",
    "\n",
    "$$\\chi_{S}(x)=\\prod_{i \\in S} \\chi\\left(x_{i}\\right)=(-1)^{\\sum_{i \\in S} x_{i}},$$\n",
    "\n",
    "which immediately follows that $\\chi_{S}(x+y)=\\chi_{S}(x) \\chi_{S}(y)$ and for $f: \\mathbb{F}_{2}^{n} \\rightarrow \\mathbb{R}$, it makes sense $f(x)=\\sum_{S \\subseteq[n]} \\widehat{f}(S) \\chi_{S}(x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1796e9-31fd-4ea6-8d67-b233cc2081f4",
   "metadata": {},
   "source": [
    "A density function on the Hamming cube  $\\mathbb{F}_{2}^{n}$  is a nonnegative function  $\\varphi: \\mathbb{F}_{2}^{n} \\rightarrow \\mathbb{R}^{\\geq 0}$  satisfying $\\underset{\\boldsymbol{x} \\sim \\mathbb{F}_{2}^{n}}{\\mathbf{E}}[\\varphi(\\boldsymbol{x})]=1$. Then we know \n",
    "\n",
    "$$ \\underset{\\boldsymbol{y} \\sim \\varphi}{\\mathbf{E}}[g(\\boldsymbol{y})]=\\langle\\varphi, g\\rangle=\\underset{\\boldsymbol{x} \\sim \\mathbb{F}_{2}^{n}}{\\mathbf{E}}[\\varphi(\\boldsymbol{x}) g(\\boldsymbol{x})]. $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc5390b-f3ad-48fe-95f8-5803bb02df83",
   "metadata": {},
   "source": [
    "> $f *(g * h)=(f * g) * h$,  $f * g=g * f$.\n",
    ">\n",
    "> $\\widehat{f * g}(\\boldsymbol{S})=\\widehat{f}(\\boldsymbol{S}) \\widehat{g}(\\boldsymbol{S})$, $\\forall S$.\n",
    "\n",
    "**Proof.** We know that\n",
    "$$\\begin{aligned}\n",
    "\\widehat{f * g}(\\boldsymbol{S}) & =\\underset{\\boldsymbol{x} \\sim \\mathbb{F}_{2}^{n}}{\\mathbf{E}}\\left[(f * g)(\\boldsymbol{x}) \\chi_{S}(\\boldsymbol{x})\\right] =\\underset{\\boldsymbol{x} \\sim \\mathbb{F}_{2}^{n}}{\\mathbf{E}}\\left[\\underset{\\boldsymbol{y} \\sim \\mathbb{F}_{2}^{n}}{\\mathbf{E}}[f(\\boldsymbol{y}) g(\\boldsymbol{x}-\\boldsymbol{y})] \\chi_{S}(\\boldsymbol{x})\\right] \\\\\n",
    "& =\\underset{\\boldsymbol{y}, \\boldsymbol{z} \\sim \\mathbb{F}_{2}^{n}}{\\mathbf{E}}\\left[f(\\boldsymbol{y}) g(\\boldsymbol{z}) \\chi_{S}(\\boldsymbol{y}+\\boldsymbol{z})\\right] =\\underset{\\boldsymbol{y}, \\boldsymbol{z} \\sim \\mathbb{F}_{2}^{n}}{\\mathbf{E}}\\left[f(\\boldsymbol{y}) \\chi_{S}(\\boldsymbol{y}) g(\\boldsymbol{z}) \\chi_{S}(\\boldsymbol{z})\\right] = \\widehat{f}(\\boldsymbol{S}) \\widehat{g}(\\boldsymbol{S}).\n",
    "\\end{aligned}$$\n",
    "\n",
    "A function  $f: \\mathbb{F}_{2}^{n} \\rightarrow \\mathbb{F}_{2} $ is linear if $f(x+y)=f(x)+f(y)$, $\\forall  x, y$, which follows that  $f(x)=a \\cdot x$. If we can query $f$'s value on just a few random inputs, then we may verify that $f$ has a certain property. This is called **property testing**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f06f23-642f-4d9b-99b6-5b430f361795",
   "metadata": {},
   "source": [
    "> ( **BLR Test** ) Given query access to  $f: \\mathbb{F}_{2}^{n} \\rightarrow \\mathbb{F}_{2} $:\n",
    "> - Choose  $\\boldsymbol{x} \\sim \\mathbb{F}_{2}^{n}$  and  $\\boldsymbol{y} \\sim \\mathbb{F}_{2}^{n}$ independently.\n",
    "> - Query  $f$  at  $x$, $y$, and $x+y$.\n",
    "> - \"Accept\" if  $f(x)+f(y)=f(x+y)$.\n",
    ">\n",
    "> **Thm.** Suppose the BLR Test accepts  $f: \\mathbb{F}_{2}^{n} \\rightarrow \\mathbb{F}_{2}$  with probability  $1-\\epsilon$. Then  $f$  is  $\\epsilon$-close to being linear."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81dcdd8-db90-4b45-bd75-32e6cacff6dd",
   "metadata": {},
   "source": [
    "**Proof.** To use Fourier transform, assume  $f \\in \\{ \\pm 1 \\}$; thus the acceptance condition becomes  $f(x) f(y)=f(x+y)$. Since\n",
    "\n",
    "$$\\frac{1}{2}+\\frac{1}{2} f(x) f(y) f(x+y)=\\left\\{\\begin{array}{ll}\n",
    "1 & \\text { if } f(x) f(y)=f(x+y) \\\\\n",
    "0 & \\text { if } f(x) f(y) \\neq f(x+y)\n",
    "\\end{array}\\right.$$\n",
    "\n",
    "we conclude\n",
    "\n",
    "$$\\begin{array}{rlr}\n",
    "1-\\epsilon=\\mathbb{P}[\\text { BLR accepts } f] & =\\underset{\\boldsymbol{x}, \\boldsymbol{y}}{\\mathbf{E}}\\left[\\frac{1}{2}+\\frac{1}{2} f(\\boldsymbol{x}) f(\\boldsymbol{y}) f(\\boldsymbol{x}+\\boldsymbol{y})\\right] & \\\\\n",
    "& =\\frac{1}{2}+\\frac{1}{2} \\underset{\\boldsymbol{x}}{\\mathbf{E}}[f(\\boldsymbol{x}) \\cdot \\underset{\\boldsymbol{y}}{\\mathbf{E}}[f(\\boldsymbol{y}) f(\\boldsymbol{x}+\\boldsymbol{y})]] & \\\\\n",
    "& =\\frac{1}{2}+\\frac{1}{2} \\underset{\\boldsymbol{x}}{\\mathbf{E}}[f(\\boldsymbol{x}) \\cdot(f * f)(\\boldsymbol{x})] & \\text { (by definition) } \\\\\n",
    "& =\\frac{1}{2}+\\frac{1}{2} \\sum_{S \\subseteq[n]} \\widehat{f}(\\boldsymbol{S}) \\widehat{f * f}(\\boldsymbol{S}) & \\text { (Plancherel) } \\\\\n",
    "& =\\frac{1}{2}+\\frac{1}{2} \\sum_{S \\subseteq[n]} \\widehat{f}(S)^{3}.\n",
    "\\end{array}$$\n",
    "\n",
    "Rearrange this equality,\n",
    "\n",
    "$$\n",
    "1-2 \\epsilon =\\sum_{S \\subseteq[n]} \\widehat{f}(S)^{3} \\leq \\max _{S \\subseteq[n]}\\{\\widehat{f}(S)\\} \\cdot \\sum_{S \\subseteq[n]} \\widehat{f}(S)^{2} =\\max _{S \\subseteq[n]}\\{\\widehat{f}(S)\\}.\n",
    "$$\n",
    "\n",
    "But  $\\widehat{f}(S)=\\left\\langle f, \\chi_{S}\\right\\rangle=1-2 \\operatorname{dist}\\left(f, \\chi_{S}\\right)$. Hence there exists some  $S^{*} \\subseteq[n]$  s.t.  $1-2 \\epsilon \\leq 1-2 \\operatorname{dist}\\left(f, \\chi_{S^{*}}\\right)$; i.e.,  $f$  is  $\\epsilon$-close to the linear function  $\\chi_{S^{*}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f5331e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Reference\n",
    "\n",
    "1. Noga Alon. The Probabilistic Method.\n",
    "2. Ryan O'Donnell. Analysis of Boolean Functions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
