{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4ecbc3a",
   "metadata": {},
   "source": [
    "## [Feb 23] Causal Inference and Transfer Learning III\n",
    "\n",
    "Presenter: Yuchen Ge  \n",
    "Affiliation: University of Oxford  \n",
    "Contact Email: gycdwwd@gmail.com  \n",
    "Website: https://yuchenge-am.github.io"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c723a98-16e1-4224-997f-2b80431b4d02",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 1.  Bayesian Method Basis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42668b62-7326-44b1-8d4e-ee3d2dcc4664",
   "metadata": {},
   "source": [
    "In a Bayesian setting, we have some unknown real-world quantity  $\\Theta$  takes values in a parameter space  $\\Omega$. Typically  $\\Omega \\subset R^{p}$. \n",
    "\n",
    "> Let  $S \\subseteq \\Omega$, is  $\\Theta$  in  $S$  ?\n",
    "\n",
    "If knowledge of the world is coherent (as is shown below), then $\\exists$ a unique **prior distribution** with density  $\\pi(\\theta)$  on  $\\Omega$ and \n",
    "\n",
    "> $$\\int_{S} \\pi(\\theta) d \\theta=\\operatorname{Pr}(\\Theta \\in S). $$\n",
    "\n",
    ">\n",
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52fab03-631b-401a-9ce7-15217dab004f",
   "metadata": {},
   "source": [
    "Observations  $Y=\\left(Y_{1}, \\ldots, Y_{n}\\right)$, $Y \\in \\mathcal{Y}$  are distributed according to an observation model with probability density  $p(y \\mid \\theta)$  for realisation  $Y=y$  with  $y=\\left(y_{1}, \\ldots, y_{n}\\right)$  given  $\\Theta=\\theta$. If the observations are iid then we have an **observation model** with probability density\n",
    "\n",
    "$$p(y \\mid \\theta)=\\prod_{i=1}^{n} p\\left(y_{i} \\mid \\theta\\right).$$\n",
    "\n",
    "Therefore, our beliefs about $\\Theta \\in S$ change with the **posterior density** of the posterior distribution being\n",
    "\n",
    "$$\\pi(S \\mid y)=\\operatorname{Pr}(\\Theta \\in S \\mid Y=y) \\pi(\\theta \\mid y)=\\frac{p(y \\mid \\theta) \\pi(\\theta)}{p(y)} \\quad \\text{ where } \\quad p(y)=\\int_{\\Omega} p(y \\mid \\theta) \\pi(\\theta) d \\theta\n",
    "$$\n",
    "\n",
    "is the normalising marginal likelihood (also, **the prior predictive distribution**). Answers to questions about  $\\Theta$  can be given in terms of  $\\pi(\\theta \\mid y)$ via $\\operatorname{Pr}(\\Theta \\in S \\mid Y=y)=\\int_{S} \\pi(\\theta \\mid y) d \\theta$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913a47d8-2041-47fa-8ba0-58502301609f",
   "metadata": {},
   "source": [
    "> Model selection in Bayesian inference has joint density $p(y, \\theta)=p(y \\mid \\theta) \\pi(\\theta)$.\n",
    ">\n",
    "> When we have latent variables  $\\psi \\sim \\pi(\\psi \\mid \\theta)$  and a generative model  $p(y \\mid \\psi) \\pi(\\psi \\mid \\theta) \\pi(\\theta)$,  the status of  $\\pi(\\psi \\mid \\theta)$  is in question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a561ad4e-6763-4e90-afac-6cd06e024415",
   "metadata": {},
   "source": [
    "Given observation model  $Y \\sim p(\\cdot \\mid \\theta)$, the  $\\Theta$-estimator $\\delta: \\mathcal{Y} \\rightarrow \\mathbb{R}^{p}$, has risk  $\\mathcal{R}(\\theta, \\delta)$  at $\\Theta=\\theta$  given by\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\mathcal{R}(\\theta, \\delta) & =E_{Y \\mid \\Theta=\\theta}(L(\\theta, \\delta(Y))) \\\\\n",
    "& =\\int_{\\mathcal{Y}} L(\\theta, \\delta(y)) p(y \\mid \\theta) d y .\n",
    "\\end{aligned}$$\n",
    "\n",
    ">  The Bayes risk,  $\\rho(\\pi, \\delta)$, is the risk averaged over the prior,\n",
    ">\n",
    "> $$\\begin{aligned}\n",
    "\\rho(\\pi, \\delta) & =E_{\\Theta}(\\mathcal{R}(\\theta, \\delta)) =E_{\\Theta, Y}(L(\\Theta, \\delta(Y))) \\\\\n",
    "& =\\int_{\\Omega} \\int_{\\mathcal{Y}} L(\\theta, \\delta(y)) p(y \\mid \\theta) \\pi(\\theta) d y d \\theta .\n",
    "\\end{aligned}$$\n",
    "> \n",
    "> if we have a prior  $\\pi(\\theta)$, posterior  $\\pi(\\theta \\mid y)$  and marginal likelihood  $p(y)$\n",
    "\n",
    "\n",
    "A Bayes estimator  $\\delta^{\\pi}$  for  $\\theta$  minimises the Bayes risk $\\delta^{\\pi}=\\arg \\min _{\\delta} \\rho(\\pi, \\delta)$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f42d1c6-1c02-4ae4-a471-b6ac9837eb4f",
   "metadata": {},
   "source": [
    "### 2. MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d9383c-5928-4760-9e42-b6bb4770fcd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de8d540-00cb-4a1b-85f9-9f152d2e47f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e424db9-32c4-4d0c-9cbe-c9096fa25430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237ebd1d-bd25-4714-b575-740836d1b55a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "98f28c99-02ff-45bf-ac85-baba30c40ef6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Reference\n",
    "\n",
    "1. Shuxiao Chen. Minimax Rates and Adaptivity in Combining Experimental and Observational Data.\n",
    "2. Qingyuan Zhao. Lecture Notes on Causal Inference. \n",
    "2. Joaquin Quiñonero-Candela. Dataset Shift In Machine Learning.\n",
    "3. Geoff K. Nicholls. Bayes Methods.\n",
    "4. Patrick J. Laub. Hawkes Processes.\n",
    "5. Tomas Björk. An Introduction to Point Processes from a Martingale Point of View."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0933978-3704-44b8-939b-460c8e7e238e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
